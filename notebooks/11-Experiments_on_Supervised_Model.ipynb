{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Working Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"core\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from core.datasets import RetinaDataset\n",
    "from core.datasets.data_augmentation import preprocess_image, preprocess_for_train\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from core.networks.resnet_with_conv import resnetconv\n",
    "from core.networks.resnet_with_conv_finetune import resnetconvfinetune\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from core.models.base import WEIGHTS_DIRNAME\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import umap\n",
    "import tf_explain\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code snippet helps if your computer has RTX 2070 GPU. If not then comment this cell.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, lb):\n",
    "  return tf.image.resize(img, (IMG_SIZE,IMG_SIZE)), tf.one_hot(lb, NCLASS)\n",
    "\n",
    "def augment_image(img, lb):\n",
    "  img, lb = resize_image(img, lb)\n",
    "  return preprocess_for_train(img, height=IMG_SIZE, width=IMG_SIZE), lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_history(history,train_type,data_fraction,batch_number):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"\\{}\\DataFraction_{}%_batch_{}_type_{}_metric_accuracy.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"\\{}\\DataFraction_{}%_batch_{}_type_{}_metric_loss.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_projection_viz(data_fraction,batch_number,model):\n",
    "    idx = 6  # index of desired layer\n",
    "    inputs = tf.keras.layers.Input((IMG_SIZE,IMG_SIZE,IMG_CH))\n",
    "    x = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "    for layer in model.layers[3:idx+1]:\n",
    "        x = layer(x)\n",
    "    new_model = tf.keras.Model(inputs, x)\n",
    "    proj_testset = new_model.predict(ds_test.map(resize_image).batch(32))\n",
    "    n_components = 3\n",
    "    l2 = np.square(proj_testset).mean(axis=-1, keepdims=True)**0.5\n",
    "    proj_normed = proj_testset / l2\n",
    "    proj_normed_pcas = PCA(n_components=n_components).fit_transform(proj_normed)\n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('PCA{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_pcas, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='PCA1', y='PCA2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"\\{}\\Projections_PCA_2D_DataFraction_{}%_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='PCA1', y='PCA2', z='PCA3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"\\{}\\Projections_PCA_3D_DataFraction_{}%_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()\n",
    "    metric = 'cosine'\n",
    "    reducer = umap.UMAP(n_components= n_components, metric=metric, n_neighbors= 50)\n",
    "    proj_normed_umap = reducer.fit_transform(proj_normed)\n",
    "    \n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('UMAP{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_umap, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='UMAP1', y='UMAP2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"\\{}\\Projections_UMAP_2D_DataFraction_{}%_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='UMAP1', y='UMAP2', z='UMAP3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"\\{}\\Projections_UMAP_3D_DataFraction_{}%_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_predictions(data_fraction,batch_number,image_list,label_list,model,layer_name='conv2d_2'):\n",
    "    global label_names\n",
    "    for i in range(len(image_list)):\n",
    "        image = image_list[i]\n",
    "        label = label_list[i]\n",
    "        label_name = label_names[label.numpy()]\n",
    "        resized_img = tf.image.resize(image, (IMG_SIZE,IMG_SIZE))\n",
    "        resized_img = tf.keras.preprocessing.image.img_to_array(resized_img)\n",
    "        expanded_img = np.expand_dims(resized_img, axis=0)\n",
    "        prediction = np.argmax(model.predict(expanded_img))\n",
    "        prediction_acc = np.max(model.predict(expanded_img))\n",
    "        predicted_label = label_names[prediction]\n",
    "\n",
    "        data = ([resized_img.astype('uint8')], None)\n",
    "        explainer = tf_explain.core.grad_cam.GradCAM()\n",
    "        grid = explainer.explain(data, model, class_index=label, layer_name=layer_name,image_weight=0.9)\n",
    "\n",
    "        explainer_occ = tf_explain.core.occlusion_sensitivity.OcclusionSensitivity()\n",
    "        grid_occ = explainer_occ.explain(data, model, class_index=label, patch_size=4)\n",
    "\n",
    "        f, ax = plt.subplots(1,3,figsize = (8,8))\n",
    "        f.suptitle(\"True label: \" + label_name+\", \"+\"Predicted label: \" + predicted_label+\", \"+\"Predicted Accuracy: \" + str(prediction_acc), fontsize=15)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].imshow(resized_img.astype('uint8'))\n",
    "        ax[1].set_title(\"Grad-CAM\")\n",
    "        ax[1].imshow(grid)\n",
    "        ax[2].set_title(\"Occlusion Sensitivity\")\n",
    "        ax[2].imshow(grid_occ)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=1.5)\n",
    "        plt.savefig(GRADCAM_PATH+\"\\{}\\GradCAM_IMG_{}_DataFraction_{}%_batch_{}.png\".format(data_fraction,i,data_fraction,batch_number))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS   = 4\n",
    "IMG_SIZE = 128\n",
    "IMG_CH = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "random.seed(7)\n",
    "BASE_PATH = Path(os.getcwd()).parent\n",
    "CHECKPOINTS_PATH = str(BASE_PATH.joinpath('core/experiment_results/checkpoints/model_weights.h5'))\n",
    "TRAINING_HISTORY_PATH= str(BASE_PATH.joinpath('core/experiment_results/training_history/'))\n",
    "CONFUSION_MATRIX_PATH = str(BASE_PATH.joinpath('core/experiment_results/confusion_matrix/'))\n",
    "PROJECTIONS_PATH = str(BASE_PATH.joinpath('core/experiment_results/projections/'))\n",
    "GRADCAM_PATH = str(BASE_PATH.joinpath('core/experiment_results/gradcam/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test, ds_test_info   = tfds.load('RetinaDataset', split='test', shuffle_files=False, as_supervised=True,with_info=True)\n",
    "test_targets = [t.numpy() for t in ds_test.map(lambda img, lb: lb).batch(BATCH_SIZE)]\n",
    "test_targets = np.hstack(test_targets)\n",
    "label_names = ds_test_info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for all the GradCAM Images\n",
    "i = 0\n",
    "images_for_gradcam = []\n",
    "lables_for_gradcam = []\n",
    "for image, label in ds_test:\n",
    "    images_for_gradcam.append(image)\n",
    "    lables_for_gradcam.append(label)\n",
    "    if i >= 2:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_store = pd.DataFrame()\n",
    "def get_results_for_data_fraction(SAMPLE_SIZE):\n",
    "    global test_targets, label_names, EPOCHS, BATCH_SIZE, images_for_gradcam, lables_for_gradcam\n",
    "    print(\"Reading and Splitting the data into batches of {}%\".format(SAMPLE_SIZE))\n",
    "    sampled_train_ds, ds_train_info = tfds.load('RetinaDataset', split=[f'train[:{k}%]+train[{k+SAMPLE_SIZE}%:]' for k in range(0, 100, SAMPLE_SIZE)], \n",
    "                                                as_supervised=True,with_info=True)\n",
    "    total_iterations = len(sampled_train_ds)\n",
    "    for ITER_COUNT in range(total_iterations):\n",
    "        print(\"Execution for batch: \"+str(ITER_COUNT))\n",
    "        ds_train = sampled_train_ds[ITER_COUNT]\n",
    "        index_for_val = random.choice([i for i in range(0,len(sampled_train_ds)) if i!=ITER_COUNT])\n",
    "        ds_val = sampled_train_ds[index_for_val]\n",
    "        ds_train_augment = ds_train.map(augment_image)\n",
    "        ds_val = ds_val.map(resize_image)\n",
    "\n",
    "        print(\"Computing weights for the classes.\")\n",
    "        y_labels = []\n",
    "        labels = ds_train_augment.map(lambda x, y: y)\n",
    "        for l in labels.batch(BATCH_SIZE).as_numpy_iterator():\n",
    "          y_labels.append(l)\n",
    "        y_labels = np.vstack(y_labels)\n",
    "        y_labels.sum(axis=0)\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', [0, 1, 2, 3], y_labels.argmax(axis=1))\n",
    "        class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "        print(\"Training the classifier.\")\n",
    "        model = resnetconv(input_shape = (IMG_SIZE, IMG_SIZE, IMG_CH), output_shape = (NCLASS,))\n",
    "        metrics = ['accuracy']\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', ),\n",
    "                     tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_PATH,monitor='val_accuracy',save_best_only=True),]\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "        history = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=0)\n",
    "        save_training_history(history,'train',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Fine-tuning the classifier.\")\n",
    "        model.layers[3].trainable = True\n",
    "        history_finetune = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=0)\n",
    "        save_training_history(history_finetune,'finetune',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Model Evaluation.\")\n",
    "        logits_testset = model.predict(ds_test.map(resize_image).batch(BATCH_SIZE))\n",
    "        ytest_pred = logits_testset.argmax(axis=-1)\n",
    "\n",
    "        print(\"Saving artifacts.\")\n",
    "        ax= plt.subplot()\n",
    "        sns_plot = sns.heatmap(confusion_matrix(test_targets, ytest_pred),annot=True,xticklabels=label_names,yticklabels=label_names,fmt='g', ax = ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(CONFUSION_MATRIX_PATH+\"\\{}\\ConfusionMatrix_DataFraction_{}%_batch_{}.png\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT))\n",
    "        plt.close()\n",
    "        accuracy = accuracy_score(test_targets, ytest_pred)\n",
    "        precision = precision_score(test_targets, ytest_pred, average='weighted')\n",
    "        recall = recall_score(test_targets, ytest_pred, average='weighted')\n",
    "        f1_sc = f1_score(test_targets, ytest_pred, average='weighted')\n",
    "        curr_metrics = pd.DataFrame({'Data_Fraction':SAMPLE_SIZE,'Batch_Number':ITER_COUNT,'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1_Score':f1_sc},index=[0])\n",
    "        metrics_store = metrics_store.append(curr_metrics,ignore_index=True)\n",
    "\n",
    "        # Saving the Model\n",
    "        model.save_weights(str(WEIGHTS_DIRNAME)+\"\\{}\\Supervised_ResNet_DataFraction_{}%_batch_{}_TestAcc_{}.h5\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT,int(accuracy*100)))\n",
    "\n",
    "        print(\"Saving Projections\")\n",
    "        save_projection_viz(SAMPLE_SIZE,ITER_COUNT,model)\n",
    "\n",
    "        print(\"Saving Saliency Maps\")\n",
    "        explain_predictions(SAMPLE_SIZE,ITER_COUNT,images_for_gradcam,lables_for_gradcam,model,layer_name=model.layers[-4].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Splitting the data into batches of 1%\n",
      "Execution for batch: 0\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Fine-tuning the classifier.\n"
     ]
    }
   ],
   "source": [
    "data_fractions_list = [1,5,10] # 1%, 5%, 10%\n",
    "for fraction in data_fractions_list:\n",
    "    clear_output(wait=True)\n",
    "    get_results_for_data_fraction(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina_env",
   "language": "python",
   "name": "retina_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
