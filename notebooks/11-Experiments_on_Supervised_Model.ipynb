{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Working Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"core\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from core.datasets import RetinaDataset\n",
    "from core.datasets.data_util import preprocess_image, preprocess_for_train\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from core.networks.resnet_with_conv import resnetconv\n",
    "from core.networks.resnet_with_conv_finetune import resnetconvfinetune\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from core.models.base import WEIGHTS_DIRNAME\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import umap\n",
    "import tf_explain\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code snippet helps if your computer has RTX 2070 GPU. If not then comment this cell.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, lb):\n",
    "  return tf.image.resize(img, (IMG_SIZE,IMG_SIZE)), tf.one_hot(lb, NCLASS)\n",
    "\n",
    "def augment_image(img, lb):\n",
    "  img, lb = resize_image(img, lb)\n",
    "  return preprocess_for_train(img, height=IMG_SIZE, width=IMG_SIZE), lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_history(history,train_type,data_fraction,batch_number):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"/{}/DataFraction_{}_batch_{}_type_{}_metric_accuracy.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"/{}/DataFraction_{}_batch_{}_type_{}_metric_loss.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_projection_viz(data_fraction,batch_number,model):\n",
    "    idx = 6  # index of desired layer\n",
    "    inputs = tf.keras.layers.Input((IMG_SIZE,IMG_SIZE,IMG_CH))\n",
    "    x = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "    for layer in model.layers[3:idx+1]:\n",
    "        x = layer(x)\n",
    "    new_model = tf.keras.Model(inputs, x)\n",
    "    proj_testset = new_model.predict(ds_test.map(resize_image).batch(32))\n",
    "    n_components = 3\n",
    "    l2 = np.square(proj_testset).mean(axis=-1, keepdims=True)**0.5\n",
    "    proj_normed = proj_testset / l2\n",
    "    proj_normed_pcas = PCA(n_components=n_components).fit_transform(proj_normed)\n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('PCA{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_pcas, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='PCA1', y='PCA2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"/{}/Projections_PCA_2D_DataFraction_{}_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='PCA1', y='PCA2', z='PCA3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"/{}/Projections_PCA_3D_DataFraction_{}%_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()\n",
    "    metric = 'cosine'\n",
    "    reducer = umap.UMAP(n_components= n_components, metric=metric, n_neighbors= 50)\n",
    "    proj_normed_umap = reducer.fit_transform(proj_normed)\n",
    "    \n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('UMAP{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_umap, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='UMAP1', y='UMAP2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"/{}/Projections_UMAP_2D_DataFraction_{}_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='UMAP1', y='UMAP2', z='UMAP3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"/{}/Projections_UMAP_3D_DataFraction_{}_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_predictions(data_fraction,batch_number,image_list,label_list,model,layer_name='conv2d_2'):\n",
    "    global label_names\n",
    "    for i in range(len(image_list)):\n",
    "        image = image_list[i]\n",
    "        label = label_list[i]\n",
    "        label_name = label_names[label.numpy()]\n",
    "        resized_img = tf.image.resize(image, (IMG_SIZE,IMG_SIZE))\n",
    "        resized_img = tf.keras.preprocessing.image.img_to_array(resized_img)\n",
    "        expanded_img = np.expand_dims(resized_img, axis=0)\n",
    "        prediction = np.argmax(model.predict(expanded_img))\n",
    "        prediction_acc = np.max(model.predict(expanded_img))\n",
    "        predicted_label = label_names[prediction]\n",
    "\n",
    "        data = ([resized_img.astype('uint8')], None)\n",
    "        explainer = tf_explain.core.grad_cam.GradCAM()\n",
    "        grid = explainer.explain(data, model, class_index=label, layer_name=layer_name,image_weight=0.9)\n",
    "\n",
    "        explainer_occ = tf_explain.core.occlusion_sensitivity.OcclusionSensitivity()\n",
    "        grid_occ = explainer_occ.explain(data, model, class_index=label, patch_size=4)\n",
    "\n",
    "        f, ax = plt.subplots(1,3,figsize = (8,8))\n",
    "        f.suptitle(\"True label: \" + label_name+\", \"+\"Predicted label: \" + predicted_label+\", \"+\"Predicted Accuracy: \" + str(prediction_acc), fontsize=15)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].imshow(resized_img.astype('uint8'))\n",
    "        ax[1].set_title(\"Grad-CAM\")\n",
    "        ax[1].imshow(grid)\n",
    "        ax[2].set_title(\"Occlusion Sensitivity\")\n",
    "        ax[2].imshow(grid_occ)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=1.5)\n",
    "        plt.savefig(GRADCAM_PATH+\"/{}/GradCAM_IMG_{}_DataFraction_{}_batch_{}.png\".format(data_fraction,i,data_fraction,batch_number))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS   = 4\n",
    "IMG_SIZE = 224\n",
    "IMG_CH = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TOTAL_ITERATIONS = 3\n",
    "random.seed(7)\n",
    "BASE_PATH = Path(os.getcwd()).parent\n",
    "CHECKPOINTS_PATH = str(BASE_PATH.joinpath('core/experiment_results/checkpoints/model_weights.h5'))\n",
    "TRAINING_HISTORY_PATH= str(BASE_PATH.joinpath('core/experiment_results/training_history/'))\n",
    "CONFUSION_MATRIX_PATH = str(BASE_PATH.joinpath('core/experiment_results/confusion_matrix/'))\n",
    "PROJECTIONS_PATH = str(BASE_PATH.joinpath('core/experiment_results/projections/'))\n",
    "GRADCAM_PATH = str(BASE_PATH.joinpath('core/experiment_results/gradcam/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test, ds_test_info   = tfds.load('RetinaDataset', split='test', shuffle_files=False, as_supervised=True,with_info=True)\n",
    "test_targets = [t.numpy() for t in ds_test.map(lambda img, lb: lb).batch(BATCH_SIZE)]\n",
    "test_targets = np.hstack(test_targets)\n",
    "label_names = ds_test_info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for all the GradCAM Images\n",
    "i = 0\n",
    "images_for_gradcam = []\n",
    "lables_for_gradcam = []\n",
    "for image, label in ds_test:\n",
    "    images_for_gradcam.append(image)\n",
    "    lables_for_gradcam.append(label)\n",
    "    if i >= 2:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_validation(ds_train, sample_percent, total_len=83489, validation_percent=0.2):\n",
    "    sample_percent_cnt = int((sample_percent/100) * total_len)\n",
    "    total_val_count = int(validation_percent * sample_percent_cnt)\n",
    "    \n",
    "#    print (sample_percent_cnt, total_val_count)\n",
    "    \n",
    "    train_sample_cnt = int(0.8*sample_percent_cnt)\n",
    " #   print (train_sample_cnt)\n",
    "    ds_train = ds_train.take(train_sample_cnt)\n",
    "    \n",
    "    ds_val, ds_val_info = tfds.load('RetinaDataset', split='train[-2%:]', as_supervised=True,with_info=True)\n",
    "    \n",
    "    ds_0 = ds_val.filter(lambda image, label: label == 0).take(total_val_count//4)\n",
    "    ds_1 = ds_val.filter(lambda image, label: label == 1).take(total_val_count //4)\n",
    "    ds_2 = ds_val.filter(lambda image, label: label == 2).take(total_val_count //4)\n",
    "    ds_3 = ds_val.filter(lambda image, label: label == 3).take(total_val_count //4)\n",
    "    \n",
    "    ds_val = ds_0.concatenate(ds_1).concatenate(ds_2).concatenate(ds_3)\n",
    "    \n",
    "    return ds_train, ds_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_store = pd.DataFrame()\n",
    "def get_results_for_data_fraction(SAMPLE_SIZE):\n",
    "    global test_targets, label_names, EPOCHS, BATCH_SIZE, images_for_gradcam, lables_for_gradcam, metrics_store, TOTAL_ITERATIONS\n",
    "    for ITER_COUNT in range(TOTAL_ITERATIONS):\n",
    "        print(\"Execution for batch: \"+str(ITER_COUNT))\n",
    "        if SAMPLE_SIZE==100:\n",
    "            ds_train, ds_train_info = tfds.load('RetinaDataset', split='train[:98%]', as_supervised=True,with_info=True)\n",
    "            ds_val, ds_val_info     = tfds.load('RetinaDataset', split='train[-2%:]', as_supervised=True,with_info=True)\n",
    "        else:\n",
    "            start_idx = int(ITER_COUNT*SAMPLE_SIZE)\n",
    "            end_idx = start_idx+SAMPLE_SIZE\n",
    "            ds_train, ds_train_info = tfds.load('RetinaDataset', split='train[{}%:{}%]'.format(start_idx,end_idx), as_supervised=True,with_info=True, shuffle_files=True)\n",
    "            ds_train, ds_val = get_train_validation(ds_train, SAMPLE_SIZE, total_len=83489, validation_percent=0.2)\n",
    "        ds_train_augment = ds_train.map(augment_image)\n",
    "        ds_val = ds_val.map(resize_image)\n",
    "\n",
    "        print(\"Computing weights for the classes.\")\n",
    "        y_labels = []\n",
    "        labels = ds_train_augment.map(lambda x, y: y)\n",
    "        for l in labels.batch(BATCH_SIZE).as_numpy_iterator():\n",
    "          y_labels.append(l)\n",
    "        y_labels = np.vstack(y_labels)\n",
    "        y_labels.sum(axis=0)\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', [0, 1, 2, 3], y_labels.argmax(axis=1))\n",
    "        class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "        print(\"Training the classifier.\")\n",
    "        model = resnetconv(input_shape = (IMG_SIZE, IMG_SIZE, IMG_CH), output_shape = (NCLASS,))\n",
    "        metrics = ['accuracy']\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', ),\n",
    "                     tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_PATH,monitor='val_accuracy',save_best_only=True),]\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.002)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "        history = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=1)\n",
    "        save_training_history(history,'train',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Fine-tuning the classifier.\")\n",
    "        model.layers[3].trainable = True\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.00005)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "        history_finetune = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=1)\n",
    "        save_training_history(history_finetune,'finetune',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Model Evaluation.\")\n",
    "        logits_testset = model.predict(ds_test.map(resize_image).batch(BATCH_SIZE))\n",
    "        ytest_pred = logits_testset.argmax(axis=-1)\n",
    "\n",
    "        print(\"Saving artifacts.\")\n",
    "        ax= plt.subplot()\n",
    "        sns_plot = sns.heatmap(confusion_matrix(test_targets, ytest_pred),annot=True,xticklabels=label_names,yticklabels=label_names,fmt='g', ax = ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(CONFUSION_MATRIX_PATH+\"/{}/ConfusionMatrix_DataFraction_{}_batch_{}.png\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT))\n",
    "        plt.close()\n",
    "        accuracy = accuracy_score(test_targets, ytest_pred)\n",
    "        precision = precision_score(test_targets, ytest_pred, average='weighted')\n",
    "        recall = recall_score(test_targets, ytest_pred, average='weighted')\n",
    "        f1_sc = f1_score(test_targets, ytest_pred, average='weighted')\n",
    "        curr_metrics = pd.DataFrame({'Data_Fraction':SAMPLE_SIZE,'Batch_Number':ITER_COUNT,'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1_Score':f1_sc},index=[0])\n",
    "        metrics_store = metrics_store.append(curr_metrics,ignore_index=True)\n",
    "\n",
    "        # Saving the Model\n",
    "        model.save_weights(str(WEIGHTS_DIRNAME)+\"/{}/Supervised_ResNet_DataFraction_{}_batch_{}_TestAcc_{}.h5\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT,int(accuracy*100)))\n",
    "\n",
    "        print(\"Saving Projections\")\n",
    "        save_projection_viz(SAMPLE_SIZE,ITER_COUNT,model)\n",
    "\n",
    "        print(\"Saving Saliency Maps\")\n",
    "        explain_predictions(SAMPLE_SIZE,ITER_COUNT,images_for_gradcam,lables_for_gradcam,model,layer_name=model.layers[-4].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution for batch: 0\n",
      "WARNING:tensorflow:From /home/rocky/miniconda3/envs/retina_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rocky/miniconda3/envs/retina_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 11.7358 - accuracy: 0.2434 - val_loss: 12.0886 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 10.6037 - accuracy: 0.5116 - val_loss: 8.5349 - val_accuracy: 0.4699\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 9.0685 - accuracy: 0.6292 - val_loss: 8.3629 - val_accuracy: 0.4729\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 8.9054 - accuracy: 0.6532 - val_loss: 8.3425 - val_accuracy: 0.4789\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 8.9605 - accuracy: 0.6390 - val_loss: 8.4635 - val_accuracy: 0.4669\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 8.8195 - accuracy: 0.6524 - val_loss: 8.3219 - val_accuracy: 0.4819\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 10s 236ms/step - loss: 8.5894 - accuracy: 0.6757 - val_loss: 8.3230 - val_accuracy: 0.4819\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 8.4218 - accuracy: 0.6884 - val_loss: 8.2667 - val_accuracy: 0.4849\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 8.4515 - accuracy: 0.6816 - val_loss: 8.4078 - val_accuracy: 0.4759\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 8.4398 - accuracy: 0.6742 - val_loss: 8.3785 - val_accuracy: 0.4759\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 10s 235ms/step - loss: 8.4515 - accuracy: 0.6704 - val_loss: 8.3061 - val_accuracy: 0.4729\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 8.3086 - accuracy: 0.6772 - val_loss: 8.2411 - val_accuracy: 0.4789\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 8.2274 - accuracy: 0.6876 - val_loss: 8.2746 - val_accuracy: 0.4639\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 8.1958 - accuracy: 0.6936 - val_loss: 8.2094 - val_accuracy: 0.4759\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 10s 237ms/step - loss: 8.1952 - accuracy: 0.6749 - val_loss: 8.1757 - val_accuracy: 0.4789\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 8.1475 - accuracy: 0.6989 - val_loss: 8.1861 - val_accuracy: 0.4789\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 8.1537 - accuracy: 0.6854 - val_loss: 8.1618 - val_accuracy: 0.4789\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 8.1489 - accuracy: 0.6899 - val_loss: 8.1671 - val_accuracy: 0.4819\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 8.1366 - accuracy: 0.6929 - val_loss: 8.1541 - val_accuracy: 0.4819\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 4.9611 - accuracy: 0.5596 - val_loss: 1.1871 - val_accuracy: 0.5452\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 1.1554 - accuracy: 0.5386 - val_loss: 1.0876 - val_accuracy: 0.6084\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 1.1167 - accuracy: 0.5573 - val_loss: 0.9751 - val_accuracy: 0.6355\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 11s 252ms/step - loss: 1.0151 - accuracy: 0.5835 - val_loss: 0.8983 - val_accuracy: 0.6627\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 0.9423 - accuracy: 0.6067 - val_loss: 0.9003 - val_accuracy: 0.7078\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.9197 - accuracy: 0.5978 - val_loss: 0.8965 - val_accuracy: 0.7229\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.8436 - accuracy: 0.6464 - val_loss: 0.8591 - val_accuracy: 0.6867\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.9011 - accuracy: 0.5903 - val_loss: 0.9106 - val_accuracy: 0.6898\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.8998 - accuracy: 0.6172 - val_loss: 0.8098 - val_accuracy: 0.7078\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.7977 - accuracy: 0.6899 - val_loss: 0.8216 - val_accuracy: 0.7259\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 0.8133 - accuracy: 0.6891 - val_loss: 0.7368 - val_accuracy: 0.7440\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 0.7913 - accuracy: 0.6652 - val_loss: 0.6770 - val_accuracy: 0.7560\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.7438 - accuracy: 0.7131 - val_loss: 0.6361 - val_accuracy: 0.7681\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.7342 - accuracy: 0.7041 - val_loss: 0.7006 - val_accuracy: 0.7590\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.7113 - accuracy: 0.7019 - val_loss: 0.7160 - val_accuracy: 0.7590\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 0.7008 - accuracy: 0.7243 - val_loss: 0.7620 - val_accuracy: 0.7380\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.6760 - accuracy: 0.7206 - val_loss: 0.7434 - val_accuracy: 0.7590\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.7320 - accuracy: 0.7191 - val_loss: 0.7040 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.7375 - accuracy: 0.7064 - val_loss: 0.6713 - val_accuracy: 0.7831\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6589 - accuracy: 0.7348 - val_loss: 0.6355 - val_accuracy: 0.7801\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.7122 - accuracy: 0.7311 - val_loss: 0.6988 - val_accuracy: 0.7801\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6522 - accuracy: 0.7371 - val_loss: 0.6405 - val_accuracy: 0.7892\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.6482 - accuracy: 0.7423 - val_loss: 0.6830 - val_accuracy: 0.7681\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6510 - accuracy: 0.7513 - val_loss: 0.6614 - val_accuracy: 0.7771\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 0.6645 - accuracy: 0.7311 - val_loss: 0.6055 - val_accuracy: 0.8012\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6395 - accuracy: 0.7543 - val_loss: 0.6653 - val_accuracy: 0.7681\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 0.6186 - accuracy: 0.7625 - val_loss: 0.7588 - val_accuracy: 0.7711\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.6119 - accuracy: 0.7581 - val_loss: 0.7292 - val_accuracy: 0.7410\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6072 - accuracy: 0.7700 - val_loss: 0.7166 - val_accuracy: 0.7741\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6336 - accuracy: 0.7603 - val_loss: 0.6584 - val_accuracy: 0.7922\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6070 - accuracy: 0.7551 - val_loss: 0.6831 - val_accuracy: 0.7771\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 0.6323 - accuracy: 0.7566 - val_loss: 0.6874 - val_accuracy: 0.7681\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 0.6063 - accuracy: 0.7655 - val_loss: 0.6742 - val_accuracy: 0.8042\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.5824 - accuracy: 0.7775 - val_loss: 0.6408 - val_accuracy: 0.8102\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.5457 - accuracy: 0.7708 - val_loss: 0.7486 - val_accuracy: 0.7651\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 1.2233 - accuracy: 0.6906 - val_loss: 0.8091 - val_accuracy: 0.7078\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 11s 258ms/step - loss: 0.7771 - accuracy: 0.6974 - val_loss: 0.7989 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.6599 - accuracy: 0.7513 - val_loss: 0.7846 - val_accuracy: 0.7440\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 11s 256ms/step - loss: 0.6164 - accuracy: 0.7610 - val_loss: 0.7948 - val_accuracy: 0.7620\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.6115 - accuracy: 0.7693 - val_loss: 0.8107 - val_accuracy: 0.7982\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.5770 - accuracy: 0.7745 - val_loss: 0.7422 - val_accuracy: 0.7952\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 12s 282ms/step - loss: 0.5194 - accuracy: 0.8037 - val_loss: 0.7071 - val_accuracy: 0.8163\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 11s 267ms/step - loss: 0.5235 - accuracy: 0.8105 - val_loss: 0.6407 - val_accuracy: 0.8133\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.4607 - accuracy: 0.8330 - val_loss: 0.7979 - val_accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.4359 - accuracy: 0.8300 - val_loss: 0.7281 - val_accuracy: 0.8343\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.4828 - accuracy: 0.8262 - val_loss: 0.8207 - val_accuracy: 0.8193\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.4475 - accuracy: 0.8195 - val_loss: 0.8117 - val_accuracy: 0.8163\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.4229 - accuracy: 0.8202 - val_loss: 0.7079 - val_accuracy: 0.8253\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.4369 - accuracy: 0.8255 - val_loss: 0.6166 - val_accuracy: 0.8193\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 11s 258ms/step - loss: 0.4391 - accuracy: 0.8247 - val_loss: 0.6618 - val_accuracy: 0.8283\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 12s 276ms/step - loss: 0.3800 - accuracy: 0.8562 - val_loss: 0.6325 - val_accuracy: 0.8645\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.3668 - accuracy: 0.8659 - val_loss: 0.7110 - val_accuracy: 0.8434\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 11s 261ms/step - loss: 0.3921 - accuracy: 0.8524 - val_loss: 0.7707 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.3852 - accuracy: 0.8562 - val_loss: 0.6934 - val_accuracy: 0.8404\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 11s 255ms/step - loss: 0.3636 - accuracy: 0.8532 - val_loss: 0.5756 - val_accuracy: 0.8614\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3378 - accuracy: 0.8547 - val_loss: 0.7321 - val_accuracy: 0.8554\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3854 - accuracy: 0.8577 - val_loss: 0.7605 - val_accuracy: 0.8524\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 11s 256ms/step - loss: 0.3259 - accuracy: 0.8861 - val_loss: 0.7773 - val_accuracy: 0.8404\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.3924 - accuracy: 0.8494 - val_loss: 0.5908 - val_accuracy: 0.8494\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 11s 261ms/step - loss: 0.3467 - accuracy: 0.8742 - val_loss: 0.6226 - val_accuracy: 0.8645\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 11s 268ms/step - loss: 0.3767 - accuracy: 0.8577 - val_loss: 0.7148 - val_accuracy: 0.8464\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3175 - accuracy: 0.8749 - val_loss: 0.6526 - val_accuracy: 0.8645\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3137 - accuracy: 0.8674 - val_loss: 0.7358 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.3268 - accuracy: 0.8801 - val_loss: 0.7593 - val_accuracy: 0.8464\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 11s 255ms/step - loss: 0.3043 - accuracy: 0.8816 - val_loss: 1.0514 - val_accuracy: 0.8163\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 1\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 11.4254 - accuracy: 0.3985 - val_loss: 10.2643 - val_accuracy: 0.3343\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 11.5588 - accuracy: 0.4030 - val_loss: 11.7637 - val_accuracy: 0.2681\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 11.0047 - accuracy: 0.4285 - val_loss: 10.8510 - val_accuracy: 0.3133\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 9.8550 - accuracy: 0.4015 - val_loss: 11.0079 - val_accuracy: 0.3133\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 11s 253ms/step - loss: 10.2259 - accuracy: 0.3805 - val_loss: 9.5522 - val_accuracy: 0.4036\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 10.3920 - accuracy: 0.4539 - val_loss: 10.2575 - val_accuracy: 0.3554\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 9.4510 - accuracy: 0.5236 - val_loss: 9.0935 - val_accuracy: 0.4277\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 9.0514 - accuracy: 0.6644 - val_loss: 8.6544 - val_accuracy: 0.4578\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 8.8639 - accuracy: 0.6824 - val_loss: 8.7233 - val_accuracy: 0.4518\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 8.9187 - accuracy: 0.6689 - val_loss: 8.4980 - val_accuracy: 0.4669\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 8.5621 - accuracy: 0.6989 - val_loss: 8.3684 - val_accuracy: 0.4789\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 8.0397 - accuracy: 0.6659 - val_loss: 7.1568 - val_accuracy: 0.5301\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 6.7421 - accuracy: 0.6120 - val_loss: 6.6675 - val_accuracy: 0.5151\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 3.0087 - accuracy: 0.5251 - val_loss: 1.1329 - val_accuracy: 0.5422\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 1.1811 - accuracy: 0.4906 - val_loss: 1.1232 - val_accuracy: 0.5030\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 11s 254ms/step - loss: 1.1199 - accuracy: 0.4966 - val_loss: 1.0776 - val_accuracy: 0.6145\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 1.0004 - accuracy: 0.6232 - val_loss: 0.9925 - val_accuracy: 0.6627\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.9926 - accuracy: 0.6689 - val_loss: 0.9676 - val_accuracy: 0.7018\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 0.9104 - accuracy: 0.6816 - val_loss: 0.9457 - val_accuracy: 0.7108\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 11s 252ms/step - loss: 0.8467 - accuracy: 0.6637 - val_loss: 0.8686 - val_accuracy: 0.7229\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 0.8638 - accuracy: 0.6891 - val_loss: 0.7891 - val_accuracy: 0.7259\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.7673 - accuracy: 0.7213 - val_loss: 0.7532 - val_accuracy: 0.7530\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 10s 229ms/step - loss: 0.7386 - accuracy: 0.7491 - val_loss: 0.7833 - val_accuracy: 0.7349\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.7151 - accuracy: 0.7423 - val_loss: 1.1069 - val_accuracy: 0.6295\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 10s 248ms/step - loss: 0.7376 - accuracy: 0.7206 - val_loss: 0.7335 - val_accuracy: 0.7801\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.7227 - accuracy: 0.7236 - val_loss: 0.8032 - val_accuracy: 0.7380\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6822 - accuracy: 0.7513 - val_loss: 0.6529 - val_accuracy: 0.7771\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6757 - accuracy: 0.7536 - val_loss: 0.6475 - val_accuracy: 0.7771\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 0.7537 - accuracy: 0.7206 - val_loss: 0.6447 - val_accuracy: 0.7831\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.6806 - accuracy: 0.7506 - val_loss: 0.6739 - val_accuracy: 0.7410\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.6510 - accuracy: 0.7640 - val_loss: 0.7755 - val_accuracy: 0.7229\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.6577 - accuracy: 0.7543 - val_loss: 0.6336 - val_accuracy: 0.7801\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 0.6501 - accuracy: 0.7603 - val_loss: 0.6698 - val_accuracy: 0.7861\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 10s 250ms/step - loss: 0.6189 - accuracy: 0.7678 - val_loss: 0.6276 - val_accuracy: 0.7892\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.6513 - accuracy: 0.7693 - val_loss: 0.6522 - val_accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.6132 - accuracy: 0.7828 - val_loss: 0.7170 - val_accuracy: 0.7651\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.6464 - accuracy: 0.7805 - val_loss: 0.6751 - val_accuracy: 0.7801\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 10s 250ms/step - loss: 0.6278 - accuracy: 0.7708 - val_loss: 0.6171 - val_accuracy: 0.8072\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.5834 - accuracy: 0.7813 - val_loss: 0.7099 - val_accuracy: 0.7831\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.6233 - accuracy: 0.7843 - val_loss: 0.7177 - val_accuracy: 0.7349\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.6221 - accuracy: 0.7596 - val_loss: 0.6765 - val_accuracy: 0.7922\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6477 - accuracy: 0.7760 - val_loss: 0.6467 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.6096 - accuracy: 0.7685 - val_loss: 0.6838 - val_accuracy: 0.7590\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.5977 - accuracy: 0.7873 - val_loss: 0.6425 - val_accuracy: 0.7831\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6032 - accuracy: 0.7903 - val_loss: 0.6523 - val_accuracy: 0.7801\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.5862 - accuracy: 0.7828 - val_loss: 0.6081 - val_accuracy: 0.7922\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.5822 - accuracy: 0.7843 - val_loss: 0.6359 - val_accuracy: 0.7771\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.5801 - accuracy: 0.7895 - val_loss: 0.5893 - val_accuracy: 0.8072\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.5741 - accuracy: 0.8060 - val_loss: 0.6052 - val_accuracy: 0.8042\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 10s 247ms/step - loss: 0.5501 - accuracy: 0.7918 - val_loss: 0.6504 - val_accuracy: 0.7590\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.5779 - accuracy: 0.7843 - val_loss: 0.6290 - val_accuracy: 0.7892\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.5156 - accuracy: 0.8022 - val_loss: 0.6246 - val_accuracy: 0.7892\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.5410 - accuracy: 0.8037 - val_loss: 0.7630 - val_accuracy: 0.7741\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.5553 - accuracy: 0.7888 - val_loss: 0.6984 - val_accuracy: 0.7590\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.5550 - accuracy: 0.8000 - val_loss: 0.8114 - val_accuracy: 0.7289\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.5697 - accuracy: 0.7888 - val_loss: 0.6730 - val_accuracy: 0.7861\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.5430 - accuracy: 0.8112 - val_loss: 0.6997 - val_accuracy: 0.7711\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 0.5399 - accuracy: 0.7940 - val_loss: 0.8021 - val_accuracy: 0.7440\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 1.4970 - accuracy: 0.6554 - val_loss: 1.7287 - val_accuracy: 0.5753\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.7939 - accuracy: 0.7221 - val_loss: 0.9862 - val_accuracy: 0.7289\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.6601 - accuracy: 0.7491 - val_loss: 0.9797 - val_accuracy: 0.7169\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 0.6579 - accuracy: 0.7528 - val_loss: 0.7694 - val_accuracy: 0.7771\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.6239 - accuracy: 0.7551 - val_loss: 0.7445 - val_accuracy: 0.7741\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 0.5890 - accuracy: 0.7730 - val_loss: 0.8487 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 11s 258ms/step - loss: 0.5125 - accuracy: 0.8052 - val_loss: 0.7172 - val_accuracy: 0.7681\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.5045 - accuracy: 0.8187 - val_loss: 0.6735 - val_accuracy: 0.8193\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.5012 - accuracy: 0.8127 - val_loss: 0.7488 - val_accuracy: 0.7952\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.4879 - accuracy: 0.8075 - val_loss: 0.5615 - val_accuracy: 0.8343\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 12s 282ms/step - loss: 0.5032 - accuracy: 0.8210 - val_loss: 0.5405 - val_accuracy: 0.8554\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 12s 274ms/step - loss: 0.4524 - accuracy: 0.8360 - val_loss: 0.5608 - val_accuracy: 0.8675\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.4254 - accuracy: 0.8472 - val_loss: 0.9863 - val_accuracy: 0.7771\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 11s 261ms/step - loss: 0.4621 - accuracy: 0.8352 - val_loss: 0.6909 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.4189 - accuracy: 0.8270 - val_loss: 0.6585 - val_accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.4301 - accuracy: 0.8427 - val_loss: 0.6296 - val_accuracy: 0.8705\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.4080 - accuracy: 0.8659 - val_loss: 0.6427 - val_accuracy: 0.8313\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 11s 257ms/step - loss: 0.3867 - accuracy: 0.8457 - val_loss: 0.6271 - val_accuracy: 0.8554\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.4050 - accuracy: 0.8509 - val_loss: 0.4852 - val_accuracy: 0.8434\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.3679 - accuracy: 0.8667 - val_loss: 0.6757 - val_accuracy: 0.8373\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 11s 261ms/step - loss: 0.3842 - accuracy: 0.8667 - val_loss: 0.6312 - val_accuracy: 0.8645\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 12s 274ms/step - loss: 0.3415 - accuracy: 0.8622 - val_loss: 0.5885 - val_accuracy: 0.8765\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 11s 256ms/step - loss: 0.3581 - accuracy: 0.8682 - val_loss: 0.6299 - val_accuracy: 0.8645\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.3458 - accuracy: 0.8704 - val_loss: 0.6693 - val_accuracy: 0.8705\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.3559 - accuracy: 0.8734 - val_loss: 0.5472 - val_accuracy: 0.8705\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 12s 277ms/step - loss: 0.3404 - accuracy: 0.8704 - val_loss: 0.5573 - val_accuracy: 0.8795\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 11s 250ms/step - loss: 0.3541 - accuracy: 0.8667 - val_loss: 0.7981 - val_accuracy: 0.8494\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.3835 - accuracy: 0.8607 - val_loss: 0.8333 - val_accuracy: 0.8524\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3445 - accuracy: 0.8659 - val_loss: 0.6669 - val_accuracy: 0.8614\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 2\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 6.6237 - accuracy: 0.3079 - val_loss: 8.0730 - val_accuracy: 0.4036\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 5.7795 - accuracy: 0.3498 - val_loss: 5.4437 - val_accuracy: 0.4669\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 11s 251ms/step - loss: 5.0120 - accuracy: 0.3903 - val_loss: 4.8273 - val_accuracy: 0.5663\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 4.8874 - accuracy: 0.3895 - val_loss: 4.9650 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 11s 252ms/step - loss: 4.7811 - accuracy: 0.3993 - val_loss: 4.5794 - val_accuracy: 0.5964\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 3.9362 - accuracy: 0.4150 - val_loss: 1.1519 - val_accuracy: 0.5633\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 1.1094 - accuracy: 0.5131 - val_loss: 0.7406 - val_accuracy: 0.7229\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 11s 252ms/step - loss: 0.9484 - accuracy: 0.6000 - val_loss: 0.6704 - val_accuracy: 0.7530\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.9172 - accuracy: 0.6240 - val_loss: 0.8503 - val_accuracy: 0.6476\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 10s 249ms/step - loss: 0.8463 - accuracy: 0.6869 - val_loss: 0.6442 - val_accuracy: 0.7590\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.7560 - accuracy: 0.7221 - val_loss: 0.7616 - val_accuracy: 0.7259\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 11s 254ms/step - loss: 0.8312 - accuracy: 0.6794 - val_loss: 0.6288 - val_accuracy: 0.7831\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.7639 - accuracy: 0.6951 - val_loss: 0.7501 - val_accuracy: 0.6867\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 10s 250ms/step - loss: 0.7248 - accuracy: 0.7139 - val_loss: 0.7364 - val_accuracy: 0.7560\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.6910 - accuracy: 0.7228 - val_loss: 0.6283 - val_accuracy: 0.7590\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.7221 - accuracy: 0.7326 - val_loss: 0.6561 - val_accuracy: 0.7831\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6577 - accuracy: 0.7408 - val_loss: 0.7053 - val_accuracy: 0.7470\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.7615 - accuracy: 0.7281 - val_loss: 0.6227 - val_accuracy: 0.7560\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 10s 237ms/step - loss: 0.6577 - accuracy: 0.7311 - val_loss: 0.6356 - val_accuracy: 0.7711\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.6941 - accuracy: 0.7296 - val_loss: 0.6481 - val_accuracy: 0.7590\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 10s 242ms/step - loss: 0.6481 - accuracy: 0.7588 - val_loss: 0.8041 - val_accuracy: 0.7229\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.6471 - accuracy: 0.7618 - val_loss: 0.7101 - val_accuracy: 0.7349\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 11s 256ms/step - loss: 0.6760 - accuracy: 0.7363 - val_loss: 0.5565 - val_accuracy: 0.7982\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6733 - accuracy: 0.7461 - val_loss: 0.5722 - val_accuracy: 0.7952\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6284 - accuracy: 0.7558 - val_loss: 0.5677 - val_accuracy: 0.7741\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 10s 237ms/step - loss: 0.6101 - accuracy: 0.7753 - val_loss: 0.6076 - val_accuracy: 0.7892\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 10s 244ms/step - loss: 0.6670 - accuracy: 0.7498 - val_loss: 0.6289 - val_accuracy: 0.7711\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.5859 - accuracy: 0.7865 - val_loss: 0.5461 - val_accuracy: 0.7861\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 10s 240ms/step - loss: 0.5753 - accuracy: 0.7760 - val_loss: 0.5646 - val_accuracy: 0.7892\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 11s 252ms/step - loss: 0.6098 - accuracy: 0.7603 - val_loss: 0.5453 - val_accuracy: 0.8012\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.6101 - accuracy: 0.7753 - val_loss: 0.5877 - val_accuracy: 0.7801\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6313 - accuracy: 0.7581 - val_loss: 0.6103 - val_accuracy: 0.7711\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.6609 - accuracy: 0.7491 - val_loss: 0.5946 - val_accuracy: 0.7922\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 10s 245ms/step - loss: 0.5556 - accuracy: 0.7858 - val_loss: 0.6859 - val_accuracy: 0.7651\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6364 - accuracy: 0.7558 - val_loss: 0.5934 - val_accuracy: 0.7801\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.6212 - accuracy: 0.7633 - val_loss: 0.6237 - val_accuracy: 0.7892\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 0.5885 - accuracy: 0.7955 - val_loss: 0.6482 - val_accuracy: 0.7560\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 10s 239ms/step - loss: 0.5303 - accuracy: 0.8037 - val_loss: 0.5749 - val_accuracy: 0.7922\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 10s 246ms/step - loss: 0.6416 - accuracy: 0.7625 - val_loss: 0.6145 - val_accuracy: 0.7801\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 0.5921 - accuracy: 0.7798 - val_loss: 0.8027 - val_accuracy: 0.6958\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 11s 258ms/step - loss: 1.2057 - accuracy: 0.6427 - val_loss: 1.0280 - val_accuracy: 0.6506\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 11s 258ms/step - loss: 0.7421 - accuracy: 0.7311 - val_loss: 0.7158 - val_accuracy: 0.7831\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.6875 - accuracy: 0.7468 - val_loss: 0.8141 - val_accuracy: 0.7771\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.6244 - accuracy: 0.7618 - val_loss: 0.5946 - val_accuracy: 0.8163\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 0.5718 - accuracy: 0.7925 - val_loss: 0.6878 - val_accuracy: 0.7801\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.6061 - accuracy: 0.7873 - val_loss: 0.8624 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 12s 281ms/step - loss: 0.5689 - accuracy: 0.7835 - val_loss: 0.6021 - val_accuracy: 0.8193\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 12s 284ms/step - loss: 0.5066 - accuracy: 0.8112 - val_loss: 0.5421 - val_accuracy: 0.8524\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.5293 - accuracy: 0.7948 - val_loss: 0.5109 - val_accuracy: 0.8675\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.4729 - accuracy: 0.8367 - val_loss: 0.4643 - val_accuracy: 0.8855\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 11s 264ms/step - loss: 0.4455 - accuracy: 0.8397 - val_loss: 0.5113 - val_accuracy: 0.8705\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 11s 266ms/step - loss: 0.4604 - accuracy: 0.8240 - val_loss: 0.5379 - val_accuracy: 0.8494\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 11s 262ms/step - loss: 0.4519 - accuracy: 0.8172 - val_loss: 0.4971 - val_accuracy: 0.8464\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 11s 265ms/step - loss: 0.3960 - accuracy: 0.8427 - val_loss: 0.5374 - val_accuracy: 0.8434\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 11s 257ms/step - loss: 0.4248 - accuracy: 0.8509 - val_loss: 0.5256 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.3864 - accuracy: 0.8509 - val_loss: 0.5803 - val_accuracy: 0.8554\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 0.3848 - accuracy: 0.8509 - val_loss: 0.6651 - val_accuracy: 0.8343\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 11s 255ms/step - loss: 0.3812 - accuracy: 0.8607 - val_loss: 0.5726 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 11s 260ms/step - loss: 0.3571 - accuracy: 0.8584 - val_loss: 0.5362 - val_accuracy: 0.8554\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 11s 259ms/step - loss: 0.3576 - accuracy: 0.8629 - val_loss: 0.4954 - val_accuracy: 0.8705\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n"
     ]
    }
   ],
   "source": [
    "data_fractions_list = [2] # 1%, 5%, 10%\n",
    "for fraction in data_fractions_list:\n",
    "#     clear_output(wait=True)\n",
    "    get_results_for_data_fraction(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Fraction</th>\n",
       "      <th>Batch_Number</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.942124</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.933835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969008</td>\n",
       "      <td>0.969281</td>\n",
       "      <td>0.969008</td>\n",
       "      <td>0.968972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973140</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.973140</td>\n",
       "      <td>0.973082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Fraction  Batch_Number  Accuracy  Precision    Recall  F1_Score\n",
       "0              2             0  0.933884   0.942124  0.933884  0.933835\n",
       "1              2             1  0.969008   0.969281  0.969008  0.968972\n",
       "2              2             2  0.973140   0.973077  0.973140  0.973082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data_Fraction    2.000000\n",
       "Batch_Number     1.000000\n",
       "Accuracy         0.958678\n",
       "Precision        0.961494\n",
       "Recall           0.958678\n",
       "F1_Score         0.958630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_store.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
