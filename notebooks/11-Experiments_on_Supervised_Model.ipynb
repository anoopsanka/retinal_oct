{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Working Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"core\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from core.datasets import RetinaDataset\n",
    "from core.datasets.data_util import preprocess_image, preprocess_for_train\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from core.networks.resnet_with_conv import resnetconv\n",
    "from core.networks.resnet_with_conv_finetune import resnetconvfinetune\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from core.models.base import WEIGHTS_DIRNAME\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import umap\n",
    "import tf_explain\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code snippet helps if your computer has RTX 2070 GPU. If not then comment this cell.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, lb):\n",
    "  return tf.image.resize(img, (IMG_SIZE,IMG_SIZE)), tf.one_hot(lb, NCLASS)\n",
    "\n",
    "def augment_image(img, lb):\n",
    "  img, lb = resize_image(img, lb)\n",
    "  return preprocess_for_train(img, height=IMG_SIZE, width=IMG_SIZE), lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_history(history,train_type,data_fraction,batch_number):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"\\{}\\DataFraction_{}%_batch_{}_type_{}_metric_accuracy.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(TRAINING_HISTORY_PATH+\"\\{}\\DataFraction_{}%_batch_{}_type_{}_metric_loss.png\".format(data_fraction,data_fraction,batch_number,train_type))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_projection_viz(data_fraction,batch_number,model):\n",
    "    idx = 6  # index of desired layer\n",
    "    inputs = tf.keras.layers.Input((IMG_SIZE,IMG_SIZE,IMG_CH))\n",
    "    x = tf.keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "    for layer in model.layers[3:idx+1]:\n",
    "        x = layer(x)\n",
    "    new_model = tf.keras.Model(inputs, x)\n",
    "    proj_testset = new_model.predict(ds_test.map(resize_image).batch(32))\n",
    "    n_components = 3\n",
    "    l2 = np.square(proj_testset).mean(axis=-1, keepdims=True)**0.5\n",
    "    proj_normed = proj_testset / l2\n",
    "    proj_normed_pcas = PCA(n_components=n_components).fit_transform(proj_normed)\n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('PCA{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_pcas, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='PCA1', y='PCA2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"\\{}\\Projections_PCA_2D_DataFraction_{}%_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='PCA1', y='PCA2', z='PCA3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"\\{}\\Projections_PCA_3D_DataFraction_{}%_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()\n",
    "    metric = 'cosine'\n",
    "    reducer = umap.UMAP(n_components= n_components, metric=metric, n_neighbors= 50)\n",
    "    proj_normed_umap = reducer.fit_transform(proj_normed)\n",
    "    \n",
    "    cols = []\n",
    "    for i in range(n_components):\n",
    "        cols.append('UMAP{}'.format(i+1))\n",
    "    df = pd.DataFrame(proj_normed_umap, columns=cols)\n",
    "    df['targets'] = test_targets\n",
    "    sns_plot = sns.kdeplot(x ='UMAP1', y='UMAP2', data= df, hue='targets', palette= sns.color_palette()[0:4])\n",
    "    fig = sns_plot.get_figure()\n",
    "    fig.savefig(PROJECTIONS_PATH+\"\\{}\\Projections_UMAP_2D_DataFraction_{}%_batch_{}.png\".format(data_fraction,data_fraction,batch_number))\n",
    "    fig = px.scatter_3d(df, x='UMAP1', y='UMAP2', z='UMAP3', color='targets')\n",
    "    plotly.offline.plot(fig, filename=PROJECTIONS_PATH+\"\\{}\\Projections_UMAP_3D_DataFraction_{}%_batch_{}.html\".format(data_fraction,data_fraction,batch_number))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_predictions(data_fraction,batch_number,image_list,label_list,model,layer_name='conv2d_2'):\n",
    "    global label_names\n",
    "    for i in range(len(image_list)):\n",
    "        image = image_list[i]\n",
    "        label = label_list[i]\n",
    "        label_name = label_names[label.numpy()]\n",
    "        resized_img = tf.image.resize(image, (IMG_SIZE,IMG_SIZE))\n",
    "        resized_img = tf.keras.preprocessing.image.img_to_array(resized_img)\n",
    "        expanded_img = np.expand_dims(resized_img, axis=0)\n",
    "        prediction = np.argmax(model.predict(expanded_img))\n",
    "        prediction_acc = np.max(model.predict(expanded_img))\n",
    "        predicted_label = label_names[prediction]\n",
    "\n",
    "        data = ([resized_img.astype('uint8')], None)\n",
    "        explainer = tf_explain.core.grad_cam.GradCAM()\n",
    "        grid = explainer.explain(data, model, class_index=label, layer_name=layer_name,image_weight=0.9)\n",
    "\n",
    "        explainer_occ = tf_explain.core.occlusion_sensitivity.OcclusionSensitivity()\n",
    "        grid_occ = explainer_occ.explain(data, model, class_index=label, patch_size=4)\n",
    "\n",
    "        f, ax = plt.subplots(1,3,figsize = (8,8))\n",
    "        f.suptitle(\"True label: \" + label_name+\", \"+\"Predicted label: \" + predicted_label+\", \"+\"Predicted Accuracy: \" + str(prediction_acc), fontsize=15)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].imshow(resized_img.astype('uint8'))\n",
    "        ax[1].set_title(\"Grad-CAM\")\n",
    "        ax[1].imshow(grid)\n",
    "        ax[2].set_title(\"Occlusion Sensitivity\")\n",
    "        ax[2].imshow(grid_occ)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=1.5)\n",
    "        plt.savefig(GRADCAM_PATH+\"\\{}\\GradCAM_IMG_{}_DataFraction_{}%_batch_{}.png\".format(data_fraction,i,data_fraction,batch_number))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS   = 4\n",
    "IMG_SIZE = 224\n",
    "IMG_CH = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TOTAL_ITERATIONS = 5\n",
    "random.seed(7)\n",
    "BASE_PATH = Path(os.getcwd()).parent\n",
    "CHECKPOINTS_PATH = str(BASE_PATH.joinpath('core/experiment_results/checkpoints/model_weights.h5'))\n",
    "TRAINING_HISTORY_PATH= str(BASE_PATH.joinpath('core/experiment_results/training_history/'))\n",
    "CONFUSION_MATRIX_PATH = str(BASE_PATH.joinpath('core/experiment_results/confusion_matrix/'))\n",
    "PROJECTIONS_PATH = str(BASE_PATH.joinpath('core/experiment_results/projections/'))\n",
    "GRADCAM_PATH = str(BASE_PATH.joinpath('core/experiment_results/gradcam/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test, ds_test_info   = tfds.load('RetinaDataset', split='test', shuffle_files=False, as_supervised=True,with_info=True)\n",
    "test_targets = [t.numpy() for t in ds_test.map(lambda img, lb: lb).batch(BATCH_SIZE)]\n",
    "test_targets = np.hstack(test_targets)\n",
    "label_names = ds_test_info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for all the GradCAM Images\n",
    "i = 0\n",
    "images_for_gradcam = []\n",
    "lables_for_gradcam = []\n",
    "for image, label in ds_test:\n",
    "    images_for_gradcam.append(image)\n",
    "    lables_for_gradcam.append(label)\n",
    "    if i >= 2:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_store = pd.DataFrame()\n",
    "def get_results_for_data_fraction(SAMPLE_SIZE):\n",
    "    global test_targets, label_names, EPOCHS, BATCH_SIZE, images_for_gradcam, lables_for_gradcam, metrics_store, TOTAL_ITERATIONS\n",
    "    for ITER_COUNT in range(TOTAL_ITERATIONS):\n",
    "        print(\"Execution for batch: \"+str(ITER_COUNT))\n",
    "        if SAMPLE_SIZE==100:\n",
    "            ds_train, ds_train_info = tfds.load('RetinaDataset', split='train[:98%]', as_supervised=True,with_info=True)\n",
    "            ds_val, ds_val_info     = tfds.load('RetinaDataset', split='train[-2%:]', as_supervised=True,with_info=True)\n",
    "        else:\n",
    "            start_idx = int(ITER_COUNT*SAMPLE_SIZE)\n",
    "            end_idx = start_idx+SAMPLE_SIZE\n",
    "            ds_train, ds_train_info = tfds.load('RetinaDataset', split='train[{}%:{}%]'.format(start_idx,end_idx), as_supervised=True,with_info=True)\n",
    "            ds_val, ds_val_info     = tfds.load('RetinaDataset', split='train[-15%:]'.format(SAMPLE_SIZE), as_supervised=True,with_info=True)\n",
    "        ds_train_augment = ds_train.map(augment_image)\n",
    "        ds_val = ds_val.map(resize_image)\n",
    "\n",
    "        print(\"Computing weights for the classes.\")\n",
    "        y_labels = []\n",
    "        labels = ds_train_augment.map(lambda x, y: y)\n",
    "        for l in labels.batch(BATCH_SIZE).as_numpy_iterator():\n",
    "          y_labels.append(l)\n",
    "        y_labels = np.vstack(y_labels)\n",
    "        y_labels.sum(axis=0)\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', [0, 1, 2, 3], y_labels.argmax(axis=1))\n",
    "        class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "        print(\"Training the classifier.\")\n",
    "        model = resnetconv(input_shape = (IMG_SIZE, IMG_SIZE, IMG_CH), output_shape = (NCLASS,))\n",
    "        metrics = ['accuracy']\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', ),\n",
    "                     tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_PATH,monitor='val_accuracy',save_best_only=True),]\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.002)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "        history = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=1)\n",
    "        save_training_history(history,'train',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Fine-tuning the classifier.\")\n",
    "        model.layers[3].trainable = True\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.00005)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "        history_finetune = model.fit(ds_train_augment.batch(BATCH_SIZE), validation_data = ds_val.batch(BATCH_SIZE), callbacks = callbacks, class_weight = class_weights, epochs=EPOCHS, verbose=1)\n",
    "        save_training_history(history_finetune,'finetune',SAMPLE_SIZE,ITER_COUNT)\n",
    "\n",
    "        print(\"Model Evaluation.\")\n",
    "        logits_testset = model.predict(ds_test.map(resize_image).batch(BATCH_SIZE))\n",
    "        ytest_pred = logits_testset.argmax(axis=-1)\n",
    "\n",
    "        print(\"Saving artifacts.\")\n",
    "        ax= plt.subplot()\n",
    "        sns_plot = sns.heatmap(confusion_matrix(test_targets, ytest_pred),annot=True,xticklabels=label_names,yticklabels=label_names,fmt='g', ax = ax)\n",
    "        ax.set_xlabel('Predicted labels')\n",
    "        ax.set_ylabel('True labels')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        fig = sns_plot.get_figure()\n",
    "        fig.savefig(CONFUSION_MATRIX_PATH+\"\\{}\\ConfusionMatrix_DataFraction_{}%_batch_{}.png\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT))\n",
    "        plt.close()\n",
    "        accuracy = accuracy_score(test_targets, ytest_pred)\n",
    "        precision = precision_score(test_targets, ytest_pred, average='weighted')\n",
    "        recall = recall_score(test_targets, ytest_pred, average='weighted')\n",
    "        f1_sc = f1_score(test_targets, ytest_pred, average='weighted')\n",
    "        curr_metrics = pd.DataFrame({'Data_Fraction':SAMPLE_SIZE,'Batch_Number':ITER_COUNT,'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1_Score':f1_sc},index=[0])\n",
    "        metrics_store = metrics_store.append(curr_metrics,ignore_index=True)\n",
    "\n",
    "        # Saving the Model\n",
    "        model.save_weights(str(WEIGHTS_DIRNAME)+\"\\{}\\Supervised_ResNet_DataFraction_{}%_batch_{}_TestAcc_{}.h5\".format(SAMPLE_SIZE,SAMPLE_SIZE,ITER_COUNT,int(accuracy*100)))\n",
    "\n",
    "        print(\"Saving Projections\")\n",
    "        save_projection_viz(SAMPLE_SIZE,ITER_COUNT,model)\n",
    "\n",
    "        print(\"Saving Saliency Maps\")\n",
    "        explain_predictions(SAMPLE_SIZE,ITER_COUNT,images_for_gradcam,lables_for_gradcam,model,layer_name=model.layers[-4].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution for batch: 0\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 84s 312ms/step - loss: 2.5027 - accuracy: 0.4745 - val_loss: 0.7163 - val_accuracy: 0.7076: 3.8489 - accuracy: 0. - ETA: 29s - loss: 3.77\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.8432 - accuracy: 0.6608 - val_loss: 0.5087 - val_accuracy: 0.8156\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.7338 - accuracy: 0.7204 - val_loss: 0.5513 - val_accuracy: 0.7956\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7174 - accuracy: 0.7219 - val_loss: 0.4736 - val_accuracy: 0.8326\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7117 - accuracy: 0.7432 - val_loss: 0.5115 - val_accuracy: 0.8065A: 39s - loss: 0.7311 - accura - ETA - ETA: 20s - loss: 0.7162 - accuracy: 0.7 - ETA: 20s - ETA: 2s - l\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6804 - accuracy: 0.7399 - val_loss: 0.4794 - val_accuracy: 0.8207\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6627 - accuracy: 0.7555 - val_loss: 0.4812 - val_accuracy: 0.821383  - ETA - ETA: 17s - loss: 0.6636 - accuracy: 0. - ETA: 16s - loss:  - ETA: 11s - loss: 0.6637 - acc - ETA: 9s - loss: 0.6634 - accuracy: 0.75 - ETA: 9s - loss: 0.6634  - ETA: 7s - - ETA: 0s - loss: 0.6628 - accuracy: 0.75\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 80s 309ms/step - loss: 0.6562 - accuracy: 0.7500 - val_loss: 0.4572 - val_accuracy: 0.8338\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6313 - accuracy: 0.7714 - val_loss: 0.4295 - val_accuracy: 0.8436\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6397 - accuracy: 0.7631 - val_loss: 0.5107 - val_accuracy: 0.8135s: 0.606\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 84s 321ms/step - loss: 0.6508 - accuracy: 0.7732 - val_loss: 0.4974 - val_accuracy: 0.8135ss: 0.6032 - accuracy: 0. - ETA: 47s - loss: 0.6107 - accuracy: 0.80 - ETA: 46s - loss: 0.6132 - accuracy: 0.80 - ETA: 46s - loss: 0.6147 - accuracy: 0 - ETA: 45s - loss: 0.6183  - ETA: 41s - loss: 0.6298 - accuracy:  - ETA: 40s - loss: 0.6331 - accuracy: - ETA: 39s - loss: 0.6374 - accuracy:  - ETA: 37s - loss: 0.64 - ETA\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6212 - accuracy: 0.7707 - val_loss: 0.4281 - val_accuracy: 0.84495s - loss: 0.6059 -  - ETA: 42s - loss: 0.5968 - accu - ETA: 40s - loss: 0.5943 - accuracy - ETA: 38s  - ETA: 7s - loss: 0.619 - ETA: 1s - loss: 0.6210 - accu\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6195 - accuracy: 0.7718 - val_loss: 0.4961 - val_accuracy: 0.8190s - loss: 0.6188 - accuracy: 0.77 - ETA: 3s - ETA: 0s - loss: 0.6194 - accuracy: 0.\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6215 - accuracy: 0.7731 - val_loss: 0.7198 - val_accuracy: 0.7304\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5946 - accuracy: 0.7835 - val_loss: 0.4609 - val_accuracy: 0.8232\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 80s 309ms/step - loss: 0.6011 - accuracy: 0.7764 - val_loss: 0.4071 - val_accuracy: 0.8508s - ETA: 12s - loss: 0\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6009 - accuracy: 0.7762 - val_loss: 0.3986 - val_accuracy: 0.8594\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5887 - accuracy: 0.7890 - val_loss: 0.5104 - val_accuracy: 0.8072 loss: 0.5503 - a - ETA: 34s - loss: - ETA: 29s - loss: 0.5659 - accuracy: 0.80 - ETA: 29s - loss: 0.5666 - acc - ETA: 17s - l - ETA: 11s - loss: 0.5843 - - ETA:  - ETA: 5s - loss: 0.5869 - accuracy - ETA: 0s - loss: 0.5886 - accuracy: \n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6172 - accuracy: 0.7795 - val_loss: 0.4466 - val_accuracy: 0.8369ss: 0.6103 - accuracy:  - ETA: 20s - loss: 0.6110  - ETA: 8s - loss: 0.615 - ETA: 6s - ETA: \n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.5946 - accuracy: 0.7849 - val_loss: 0.4389 - val_accuracy: 0.840548s - loss: 0.5368 - accuracy: 0.7 - ETA: 47s - loss: 0.5448 -  - ETA: 44s - loss: 0.565 - ETA: 2s - loss: 0.5941 - accuracy: 0. - ETA: 2s - loss: 0.5942 - accuracy: 0. - ETA: 1s - loss: 0.5943 - accuracy:  - ETA: 1s - loss: 0.5944 - ac\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5944 - accuracy: 0.7765 - val_loss: 0.5031 - val_accuracy: 0.8061curacy: 0.7 - ETA: 29s - loss - ETA: 24s - loss: 0. - ETA:  - ETA: 6s - loss: 0\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5734 - accuracy: 0.7887 - val_loss: 0.4308 - val_accuracy: 0.8442\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6176 - accuracy: 0.7812 - val_loss: 0.4267 - val_accuracy: 0.8421.7 -  - ETA: 1s - loss: 0.6173 \n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5840 - accuracy: 0.7949 - val_loss: 0.3903 - val_accuracy: 0.8628 - ETA: 22s - loss: 0.5887 - accura - ETA: 20s - loss: 0.5884 - accuracy: 0.79 - ETA: 20 - ETA: 7s - l\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5832 - accuracy: 0.7861 - val_loss: 0.4029 - val_accuracy: 0.8604: 0.5780 - accuracy: 0.7 - ETA: 28s - ETA: 6s - los\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5861 - accuracy: 0.7920 - val_loss: 0.3944 - val_accuracy: 0.8578oss: 0.5865 - a - ETA: 42s - loss: 0.5826 - accuracy:  - ETA: 40s - loss: 0.5815 - accur - ETA: 38s - loss: 0.5832 - accuracy:  - ETA: 3 - ETA: 30s - loss: 0.5878 - accuracy: - ETA:  - - ETA: 6s - loss: 0.5890 - accuracy:  - ETA: 6s - loss: 0.5\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5947 - accuracy: 0.7959 - val_loss: 0.4086 - val_accuracy: 0.85495669 - accu - ETA: 43s - loss: 0.5786 - a - ETA: 4 - ETA: 33s - lo - ETA: 18s - loss: 0.5950 - accuracy: 0 - ETA: 17s -  - ETA: 11s - loss: 0.595\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5833 - accuracy: 0.8000 - val_loss: 0.4630 - val_accuracy: 0.8277\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5902 - accuracy: 0.7860 - val_loss: 0.4373 - val_accuracy: 0.8411\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5810 - accuracy: 0.7898 - val_loss: 0.4538 - val_accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5656 - accuracy: 0.7974 - val_loss: 0.3998 - val_accuracy: 0.8551488 - accuracy: 0 - ETA: 31s - loss: 0.5504 - accuracy: 0 - ETA: 30s - l - ETA: 24s - lo - ETA: 18s - loss: 0.5602 - accuracy: 0. - ETA: 17s - loss: 0.5606 - accurac - ETA: 15s - loss: 0.5613 - accuracy:  - ETA: 1\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5499 - accuracy: 0.8032 - val_loss: 0.4581 - val_accuracy: 0.8254 - accurac - ETA: 41s - loss: 0.5114 -  - ETA: 38s - l - ETA: 32s - lo - ETA:  - ETA: 19s - loss: 0.5391 - accurac - ETA: 17s -  - ETA: 11s - loss: 0.5444 - accuracy: - E - ETA: 5s - loss: 0.5470 \n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 80s 309ms/step - loss: 0.5588 - accuracy: 0.7891 - val_loss: 0.4624 - val_accuracy: 0.8268\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5684 - accuracy: 0.7804 - val_loss: 0.3882 - val_accuracy: 0.86142s - loss: 0.537 - ET - ETA: 30s - loss: 0.5624 - accuracy - ETA: 29s - loss: 0.5637 - ac - ETA: 26s - loss: 0.5650 - accuracy: 0. - ETA: 25s - loss:  - ETA: 1s - loss: 0.5\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5698 - accuracy: 0.7887 - val_loss: 0.4171 - val_accuracy: 0.8460\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5699 - accuracy: 0.7880 - val_loss: 0.3669 - val_accuracy: 0.8744\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5708 - accuracy: 0.7978 - val_loss: 0.4260 - val_accuracy: 0.8448: 50s - - ETA: 17s - loss: - - ETA: 2s - loss: 0.5707 - accuracy:  - ETA: 1s - loss: 0.570\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5598 - accuracy: 0.7969 - val_loss: 0.4149 - val_accuracy: 0.8487\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5862 - accuracy: 0.7867 - val_loss: 0.4917 - val_accuracy: 0.8212- loss: 0.5752 - accuracy - ETA: 0s - loss: 0.5864 - accu\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5514 - accuracy: 0.8034 - val_loss: 0.4226 - val_accuracy: 0.8466 ETA: 33s - loss: 0.5391 - accuracy: - ETA: 23\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5339 - accuracy: 0.8052 - val_loss: 0.4472 - val_accuracy: 0.8348- ETA: 42s - loss: 0.4865 - accuracy - ETA: 41s -  - ETA: 34s - loss: 0.5 - ETA: 30s - loss: \n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5537 - accuracy: 0.8045 - val_loss: 0.4026 - val_accuracy: 0.8541: 36s - loss: 0.5303 - - ETA: 33s - loss: 0.5352 - accuracy: 0. - ETA: 3\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5503 - accuracy: 0.7966 - val_loss: 0.3779 - val_accuracy: 0.8678\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5427 - accuracy: 0.8097 - val_loss: 0.4482 - val_accuracy: 0.8327\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5217 - accuracy: 0.8106 - val_loss: 0.4230 - val_accuracy: 0.8430\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5512 - accuracy: 0.8046 - val_loss: 0.4248 - val_accuracy: 0.8453\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.9193 - accuracy: 0.7013 - val_loss: 0.4463 - val_accuracy: 0.8418\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.5695 - accuracy: 0.7888 - val_loss: 0.3344 - val_accuracy: 0.8869\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4904 - accuracy: 0.8184 - val_loss: 0.3193 - val_accuracy: 0.9003\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4622 - accuracy: 0.8324 - val_loss: 0.2606 - val_accuracy: 0.9196\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4359 - accuracy: 0.8401 - val_loss: 0.2478 - val_accuracy: 0.9234\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.4070 - accuracy: 0.8525 - val_loss: 0.2366 - val_accuracy: 0.9193\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3994 - accuracy: 0.8549 - val_loss: 0.2514 - val_accuracy: 0.9201\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3782 - accuracy: 0.8605 - val_loss: 0.2608 - val_accuracy: 0.9129\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3621 - accuracy: 0.8622 - val_loss: 0.2509 - val_accuracy: 0.9124\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3656 - accuracy: 0.8648 - val_loss: 0.2313 - val_accuracy: 0.9295\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3627 - accuracy: 0.8678 - val_loss: 0.2383 - val_accuracy: 0.9225\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3522 - accuracy: 0.8722 - val_loss: 0.2619 - val_accuracy: 0.9183\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3600 - accuracy: 0.8705 - val_loss: 0.2101 - val_accuracy: 0.9390\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3504 - accuracy: 0.8764 - val_loss: 0.2045 - val_accuracy: 0.9370\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3266 - accuracy: 0.8809 - val_loss: 0.2226 - val_accuracy: 0.9316\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3395 - accuracy: 0.8732 - val_loss: 0.2202 - val_accuracy: 0.9304\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3391 - accuracy: 0.8699 - val_loss: 0.2338 - val_accuracy: 0.9221\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3225 - accuracy: 0.8775 - val_loss: 0.2123 - val_accuracy: 0.9396\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3308 - accuracy: 0.8753 - val_loss: 0.2132 - val_accuracy: 0.9431\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3121 - accuracy: 0.8939 - val_loss: 0.1927 - val_accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2950 - accuracy: 0.8945 - val_loss: 0.2183 - val_accuracy: 0.9390\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 90s 345ms/step - loss: 0.3246 - accuracy: 0.8869 - val_loss: 0.2194 - val_accuracy: 0.9342\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3113 - accuracy: 0.8844 - val_loss: 0.2507 - val_accuracy: 0.9255\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3225 - accuracy: 0.8863 - val_loss: 0.2146 - val_accuracy: 0.9308\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2900 - accuracy: 0.8951 - val_loss: 0.2259 - val_accuracy: 0.9380\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2925 - accuracy: 0.8949 - val_loss: 0.2464 - val_accuracy: 0.9277\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3057 - accuracy: 0.8942 - val_loss: 0.2294 - val_accuracy: 0.9314\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3035 - accuracy: 0.8858 - val_loss: 0.2133 - val_accuracy: 0.9344\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.2739 - accuracy: 0.9000 - val_loss: 0.2136 - val_accuracy: 0.9407\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.2880 - accuracy: 0.8959 - val_loss: 0.1947 - val_accuracy: 0.9478\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 1\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 2.7344 - accuracy: 0.5058 - val_loss: 0.6873 - val_accuracy: 0.752438 - accur - ETA:  - ETA: 33s - loss: 4.5233 - accuracy:  - ETA: 23s - lo - ETA: 9s - l - ETA: 6s - loss: - ETA\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.8755 - accuracy: 0.6852 - val_loss: 0.5741 - val_accuracy: 0.8036s: 0.8912 - accuracy: 0.68 - ETA: 30s - loss: 0.8909 -  - ETA: 27s - loss: 0.8891 - accuracy: - ETA: 25s - loss: 0.88 - ETA: 2s - loss:\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7889 - accuracy: 0.7063 - val_loss: 0.6052 - val_accuracy: 0.7770  - ETA: 1s - loss: 0.7\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.7626 - accuracy: 0.7218 - val_loss: 0.5685 - val_accuracy: 0.7958\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7366 - accuracy: 0.7412 - val_loss: 0.5608 - val_accuracy: 0.7961s: 0.7435 - accur - ETA: 22s - loss: 0.738 - ETA: 18s - loss: 0.7 - ETA: 13s \n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.7227 - accuracy: 0.7431 - val_loss: 0.5327 - val_accuracy: 0.8087\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.7251 - accuracy: 0.7469 - val_loss: 0.5857 - val_accuracy: 0.7854\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6869 - accuracy: 0.7586 - val_loss: 0.5937 - val_accuracy: 0.7879 loss: 0.6870 - accuracy: 0.75 - ETA: 5s - loss: 0.6870 - accuracy: 0. - ETA: 5s - l - ETA: 2s - loss: 0\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6994 - accuracy: 0.7513 - val_loss: 0.4994 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.7012 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.8111\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6829 - accuracy: 0.7623 - val_loss: 0.5052 - val_accuracy: 0.8206947 - accuracy: - ETA: 32s - loss: 0.6932 - accuracy: 0.7 - ETA: 31s - loss:  - ETA: 26s - loss: 0.6905 - accuracy: 0.75 - ETA: 26s - ETA: 1s - loss: 0.6834 - ac\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6698 - accuracy: 0.7682 - val_loss: 0.5100 - val_accuracy: 0.8248accuracy: 0.76 - ETA: 45s - loss: 0.6851 - accurac - ETA: 34s - loss: 0.6764 - accuracy: 0  - ET\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6514 - accuracy: 0.7804 - val_loss: 0.5233 - val_accuracy: 0.8116oss: 0.6410 - accura - ETA: 27s - loss: 0.6419 - accuracy\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6607 - accuracy: 0.7725 - val_loss: 0.6009 - val_accuracy: 0.78829 - ETA: 16s - loss: 0.6619 - accura - ETA: 14s - loss: 0.6621 - accuracy - ETA: 6s - loss: - ETA: 4s - ETA: 0s - loss: 0.6609 - accuracy\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6692 - accuracy: 0.7638 - val_loss: 0.4510 - val_accuracy: 0.8408\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6408 - accuracy: 0.7796 - val_loss: 0.6024 - val_accuracy: 0.7901\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6527 - accuracy: 0.7686 - val_loss: 0.4571 - val_accuracy: 0.840926s - loss: 0.6664 - accuracy: - ETA: 25s - loss: 0.6658 - accuracy: 0 - ET - ETA: 16s - loss: 0. - ETA: 11s - loss: 0.6582 - accuracy: 0 - ETA: 10s - loss: 0.6577 - ETA: 3s - loss: 0.6541 - accu - ETA: 2s - loss: 0.653 - ETA: 0s - loss: 0.6530 - accuracy\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6365 - accuracy: 0.7768 - val_loss: 0.5344 - val_accuracy: 0.8077\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6528 - accuracy: 0.7715 - val_loss: 0.4817 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6357 - accuracy: 0.7770 - val_loss: 0.4645 - val_accuracy: 0.8350\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6334 - accuracy: 0.7833 - val_loss: 0.4585 - val_accuracy: 0.8348A: 47s - loss: 0.6668 - accuracy: 0.77 - ETA: 47s - loss: 0.6661 - accuracy:  - ETA: 46s - loss: 0.6630 - accuracy: 0. - ETA: 45s - ETA: 37s - loss: 0.6500 - accuracy: 0.779 - ETA: 10s - loss: 0.6360 - accuracy: 0.78 - ETA - ETA: 1s - loss: 0.6339 \n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6339 - accuracy: 0.7809 - val_loss: 0.4597 - val_accuracy: 0.8373\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6095 - accuracy: 0.7925 - val_loss: 0.4473 - val_accuracy: 0.8393\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6241 - accuracy: 0.7882 - val_loss: 0.4667 - val_accuracy: 0.8325\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6170 - accuracy: 0.7855 - val_loss: 0.4714 - val_accuracy: 0.8357racy: - ETA: 15s - ETA: 4s - loss: 0.6178 - accuracy - ETA: 3s - loss: 0.6177 - accura - ETA: 2s - l\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6329 - accuracy: 0.7810 - val_loss: 0.4174 - val_accuracy: 0.8547\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6247 - accuracy: 0.7863 - val_loss: 0.4698 - val_accuracy: 0.8329\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6197 - accuracy: 0.7867 - val_loss: 0.4880 - val_accuracy: 0.8231 13s - loss: 0.6199 - accur - ETA: 1s - loss: 0.6198 \n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.6038 - accuracy: 0.7964 - val_loss: 0.4762 - val_accuracy: 0.8379\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6022 - accuracy: 0.7866 - val_loss: 0.4037 - val_accuracy: 0.8562\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.5783 - accuracy: 0.8070 - val_loss: 0.4505 - val_accuracy: 0.8408\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6057 - accuracy: 0.7986 - val_loss: 0.4759 - val_accuracy: 0.8335\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6077 - accuracy: 0.7928 - val_loss: 0.4633 - val_accuracy: 0.8392\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6077 - accuracy: 0.7928 - val_loss: 0.4500 - val_accuracy: 0.8438\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.5836 - accuracy: 0.8013 - val_loss: 0.4754 - val_accuracy: 0.8349\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.5961 - accuracy: 0.7896 - val_loss: 0.4704 - val_accuracy: 0.8347\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.6206 - accuracy: 0.7847 - val_loss: 0.4679 - val_accuracy: 0.8374\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.5778 - accuracy: 0.7984 - val_loss: 0.4523 - val_accuracy: 0.8374\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.5817 - accuracy: 0.7999 - val_loss: 0.4844 - val_accuracy: 0.8274\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.5883 - accuracy: 0.7976 - val_loss: 0.3941 - val_accuracy: 0.8643\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 81s 311ms/step - loss: 0.6179 - accuracy: 0.7829 - val_loss: 0.4725 - val_accuracy: 0.8327\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 81s 312ms/step - loss: 0.5977 - accuracy: 0.7901 - val_loss: 0.3789 - val_accuracy: 0.8670\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.5689 - accuracy: 0.8023 - val_loss: 0.4425 - val_accuracy: 0.8465 loss: - ETA: 21 - ETA: 14s - loss: 0.5668 - acc - ETA: - ETA: 2s - loss: 0.5 - ETA: 0s - loss: 0.5688 - accuracy: \n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.5782 - accuracy: 0.7982 - val_loss: 0.4024 - val_accuracy: 0.85940.5782 - accura\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5923 - accuracy: 0.7911 - val_loss: 0.4302 - val_accuracy: 0.8487- loss: 0.6240 - accuracy: - ETA: 45s - loss: 0.6158 - accuracy:  - ETA: 44s - loss: - ETA: 30s - loss: 0.5966 - accuracy: 0.79 - ETA: 30s - loss: 0.5966 - accuracy: 0. - ETA: 29s - loss: 0.5966 - acc - ETA: 26s - loss: 0.5962 - accuracy: 0.794 - ETA: 26s - loss: 0.5962 - accuracy: 0.7 - ETA: 25s - loss: 0.5961 - accuracy: 0.79 - ETA: 25 - ETA: 18s - loss: 0.5 - ETA: 7s - loss: 0.5940 - accuracy:  - ETA: 6s - loss:\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 82s 315ms/step - loss: 0.5899 - accuracy: 0.7932 - val_loss: 0.4142 - val_accuracy: 0.8545\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 82s 316ms/step - loss: 0.5980 - accuracy: 0.8039 - val_loss: 0.4378 - val_accuracy: 0.8496\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 82s 316ms/step - loss: 0.5720 - accuracy: 0.8051 - val_loss: 0.4039 - val_accuracy: 0.8627\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 82s 316ms/step - loss: 0.5976 - accuracy: 0.7983 - val_loss: 0.3933 - val_accuracy: 0.8641\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 82s 316ms/step - loss: 0.5546 - accuracy: 0.8070 - val_loss: 0.4264 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 83s 316ms/step - loss: 0.5921 - accuracy: 0.8038 - val_loss: 0.4652 - val_accuracy: 0.8386\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 83s 317ms/step - loss: 0.5760 - accuracy: 0.7930 - val_loss: 0.4596 - val_accuracy: 0.8386\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 1.1124 - accuracy: 0.6926 - val_loss: 0.6189 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.6351 - accuracy: 0.7824 - val_loss: 0.4212 - val_accuracy: 0.8657\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.5380 - accuracy: 0.8151 - val_loss: 0.2879 - val_accuracy: 0.9114\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.4784 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.9235\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.4670 - accuracy: 0.8397 - val_loss: 0.3201 - val_accuracy: 0.8974\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 93s 357ms/step - loss: 0.4258 - accuracy: 0.8454 - val_loss: 0.2444 - val_accuracy: 0.9245\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 93s 358ms/step - loss: 0.4137 - accuracy: 0.8540 - val_loss: 0.2554 - val_accuracy: 0.9184\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.4184 - accuracy: 0.8433 - val_loss: 0.2644 - val_accuracy: 0.9178\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 93s 357ms/step - loss: 0.4203 - accuracy: 0.8476 - val_loss: 0.2252 - val_accuracy: 0.9275\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3884 - accuracy: 0.8620 - val_loss: 0.2788 - val_accuracy: 0.9147\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3533 - accuracy: 0.8674 - val_loss: 0.2235 - val_accuracy: 0.9312\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 94s 359ms/step - loss: 0.3919 - accuracy: 0.8637 - val_loss: 0.2609 - val_accuracy: 0.9190\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3667 - accuracy: 0.8715 - val_loss: 0.2684 - val_accuracy: 0.9163\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.3785 - accuracy: 0.8672 - val_loss: 0.2693 - val_accuracy: 0.9181\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.3464 - accuracy: 0.8726 - val_loss: 0.2142 - val_accuracy: 0.9316\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 93s 354ms/step - loss: 0.3488 - accuracy: 0.8769 - val_loss: 0.2733 - val_accuracy: 0.9208\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.3275 - accuracy: 0.8824 - val_loss: 0.2086 - val_accuracy: 0.9346\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3246 - accuracy: 0.8802 - val_loss: 0.3201 - val_accuracy: 0.8928\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3223 - accuracy: 0.8807 - val_loss: 0.2075 - val_accuracy: 0.9381\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 92s 354ms/step - loss: 0.3441 - accuracy: 0.8781 - val_loss: 0.2033 - val_accuracy: 0.9426\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.3379 - accuracy: 0.8780 - val_loss: 0.2362 - val_accuracy: 0.9379\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3392 - accuracy: 0.8776 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3334 - accuracy: 0.8817 - val_loss: 0.3426 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 93s 357ms/step - loss: 0.3209 - accuracy: 0.8835 - val_loss: 0.2036 - val_accuracy: 0.9351\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3063 - accuracy: 0.8922 - val_loss: 0.2675 - val_accuracy: 0.9179\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.3071 - accuracy: 0.8906 - val_loss: 0.1933 - val_accuracy: 0.9447\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 93s 356ms/step - loss: 0.2906 - accuracy: 0.8927 - val_loss: 0.1994 - val_accuracy: 0.9455\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 93s 355ms/step - loss: 0.2902 - accuracy: 0.8957 - val_loss: 0.2164 - val_accuracy: 0.9332\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 92s 351ms/step - loss: 0.2894 - accuracy: 0.8993 - val_loss: 0.1916 - val_accuracy: 0.9454\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 91s 349ms/step - loss: 0.2987 - accuracy: 0.8893 - val_loss: 0.2141 - val_accuracy: 0.9420\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 91s 349ms/step - loss: 0.2779 - accuracy: 0.8951 - val_loss: 0.2064 - val_accuracy: 0.9456\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.2956 - accuracy: 0.8981 - val_loss: 0.2710 - val_accuracy: 0.9205\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 2\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 81s 308ms/step - loss: 2.0336 - accuracy: 0.4650 - val_loss: 0.5906 - val_accuracy: 0.7908A: 31s\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.7996 - accuracy: 0.7173 - val_loss: 0.5889 - val_accuracy: 0.7794TA: 0s - loss: 0.7999 - accura\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7492 - accuracy: 0.7262 - val_loss: 0.5729 - val_accuracy: 0.7880\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7230 - accuracy: 0.7462 - val_loss: 0.5212 - val_accuracy: 0.8154A: 50s - loss: 0.9825 - accuracy: 0. - ETA: 50s - loss: 0.9392 -  - ETA: 46s - loss: 0.823 - ETA: 42s - loss: 0. - ETA: 38s - loss: 0.755\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6820 - accuracy: 0.7551 - val_loss: 0.4617 - val_accuracy: 0.8385loss: 0.6699 - accurac - ETA: 32s - loss: 0.6701 - acc - ETA: 29s - loss: 0.6711 - accuracy: 0.7 - ETA: 29s - loss: 0.6712 - accuracy: - ETA: 27s - loss: 0.67 - ETA: 23s - loss: 0.6736 - accuracy: 0.756 - - ETA: \n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6522 - accuracy: 0.7706 - val_loss: 0.4424 - val_accuracy: 0.8439\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6762 - accuracy: 0.7603 - val_loss: 0.4306 - val_accuracy: 0.8427 47s - loss: 0.7639 - - ETA: 44s - loss: 0. - ETA: 39s - loss - ETA: 3 - ETA: 26s - lo - ETA: 6s - loss: 0\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6343 - accuracy: 0.7691 - val_loss: 0.5405 - val_accuracy: 0.7993 loss: 0.6271 - accuracy - ETA: 17s - loss: 0.6300 - accur - ETA: \n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6565 - accuracy: 0.7702 - val_loss: 0.5483 - val_accuracy: 0.8019s - loss: 0.6564 - accu - ETA: 0s - loss: 0.6565 - accuracy: 0.\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6276 - accuracy: 0.7714 - val_loss: 0.4579 - val_accuracy: 0.8349\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.6405 - accuracy: 0.7646 - val_loss: 0.4836 - val_accuracy: 0.8179 - loss:\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6535 - accuracy: 0.7676 - val_loss: 0.4283 - val_accuracy: 0.8466 ETA: 19s - loss: 0.6592 - acc - ETA: 17s - loss: 0.6587 -  - ETA: 13s \n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6387 - accuracy: 0.7782 - val_loss: 0.4729 - val_accuracy: 0.8225y: 0.7 - ETA: 43s - loss: 0.7010 - accuracy: 0 - ETA: 42s - loss: 0.6939 - accuracy: - ETA: 41s - loss: 0.6843 - accur - ETA: 20s - loss: 0.6421 - accuracy: 0.78 - ETA: 20s - loss: 0.6420 - accur - ETA: 18s - loss: 0.6416 - accur\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6302 - accuracy: 0.7758 - val_loss: 0.4105 - val_accuracy: 0.8466 loss: 0.6302 - \n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6085 - accuracy: 0.7795 - val_loss: 0.4484 - val_accuracy: 0.8345 - ETA: 9s - l - ETA: 6s - loss: 0.6083 - accura - ETA: 5s - loss: 0.6 - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.6084 - accura\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 81s 308ms/step - loss: 0.6427 - accuracy: 0.7705 - val_loss: 0.4355 - val_accuracy: 0.835369 - accuracy: 0.769 - ETA: 27s - loss: 0.6468 - accuracy: 0 - ETA: 26s - loss: 0.6467 - accuracy: \n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6061 - accuracy: 0.7850 - val_loss: 0.4424 - val_accuracy: 0.8422: 0.6004 - accur - ETA: 15s - loss: 0.6011 - accuracy: 0. - ETA: 15 - ETA: 0s - loss: 0.6060 - accuracy: 0.\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6035 - accuracy: 0.7820 - val_loss: 0.4557 - val_accuracy: 0.8331oss: 0.6531 - accuracy: 0.76 - ETA: 46s  - ETA: 21s - ETA: 14s - loss: 0.6033 - accuracy: 0 - E - ETA: \n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6225 - accuracy: 0.7712 - val_loss: 0.4685 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5950 - accuracy: 0.7829 - val_loss: 0.5648 - val_accuracy: 0.7941- ETA: 0s - loss: 0.5948 - accu\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6060 - accuracy: 0.7890 - val_loss: 0.4396 - val_accuracy: 0.8393ccuracy:  - ETA: 25s - loss: 0.613 - ETA: 21s - loss: 0.6114 - acc - ETA: 19s - loss: 0.6104 - accuracy: 0.79 -  - ETA: 1s - loss: 0.6063 - \n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5859 - accuracy: 0.7903 - val_loss: 0.4422 - val_accuracy: 0.8417 - ac - ETA: 1\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5928 - accuracy: 0.7813 - val_loss: 0.3802 - val_accuracy: 0.864468 - ETA: 35s - loss: 0.6176 - accuracy:  - ETA: - ETA: 18s - loss: 0. - ETA: 13s - loss: 0.5959 - accuracy:  - ETA: 12s - l - E\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6124 - accuracy: 0.7694 - val_loss: 0.5096 - val_accuracy: 0.8176 45s - loss: 0.66 - ETA:  - ETA: 33s - loss: 0.6275 - ac - ETA: 30s - loss: 0.6 - ETA: 26s - loss: 0.6195 - acc - ETA: 14s - loss: 0.6163 - accuracy: - ETA: 13s - l\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5831 - accuracy: 0.7794 - val_loss: 0.4601 - val_accuracy: 0.8320loss: 0.5923 - - ETA: 33s - loss: 0.588 - ETA: 29s - loss: 0.58\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6041 - accuracy: 0.7792 - val_loss: 0.4111 - val_accuracy: 0.8533\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5893 - accuracy: 0.7869 - val_loss: 0.4253 - val_accuracy: 0.8508\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 81s 310ms/step - loss: 0.5868 - accuracy: 0.7821 - val_loss: 0.3813 - val_accuracy: 0.8673\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5777 - accuracy: 0.7928 - val_loss: 0.4211 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5730 - accuracy: 0.7994 - val_loss: 0.3958 - val_accuracy: 0.862186 - accuracy: 0 - ETA: 40s - los\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5840 - accuracy: 0.7945 - val_loss: 0.5471 - val_accuracy: 0.8052- loss: 0.5842 - accuracy: 0 - ETA: 19s - loss: 0 - ETA: 14s - loss: 0.5844 - ac - ETA: 2s - loss: 0.584 - ETA: 0s - loss: 0.5840 - accuracy: 0.\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 81s 308ms/step - loss: 0.5766 - accuracy: 0.7956 - val_loss: 0.4331 - val_accuracy: 0.8389 ETA: 33s - loss: 0.5683 - acc -  - ETA: 22s - los - - ETA: 0s - loss: 0.5764 - accuracy\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5844 - accuracy: 0.7973 - val_loss: 0.4295 - val_accuracy: 0.8481A: 47s - loss: 0.6455 - accuracy: 0 - ETA: 46s - loss: 0.64 - E\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.8699 - accuracy: 0.7071 - val_loss: 0.3800 - val_accuracy: 0.8750\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.5983 - accuracy: 0.7643 - val_loss: 0.3118 - val_accuracy: 0.8945\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.4989 - accuracy: 0.8111 - val_loss: 0.2843 - val_accuracy: 0.9018\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4648 - accuracy: 0.8198 - val_loss: 0.2904 - val_accuracy: 0.9029\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.4537 - accuracy: 0.8244 - val_loss: 0.3629 - val_accuracy: 0.8691\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.4343 - accuracy: 0.8340 - val_loss: 0.3594 - val_accuracy: 0.8743\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.4394 - accuracy: 0.8357 - val_loss: 0.3646 - val_accuracy: 0.8758\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.3877 - accuracy: 0.8589 - val_loss: 0.2314 - val_accuracy: 0.9202\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3870 - accuracy: 0.8518 - val_loss: 0.1931 - val_accuracy: 0.9371\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3455 - accuracy: 0.8689 - val_loss: 0.2163 - val_accuracy: 0.9289\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.3537 - accuracy: 0.8695 - val_loss: 0.2702 - val_accuracy: 0.9185\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.3523 - accuracy: 0.8714 - val_loss: 0.2116 - val_accuracy: 0.9328\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.3533 - accuracy: 0.8690 - val_loss: 0.3344 - val_accuracy: 0.8998\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3459 - accuracy: 0.8757 - val_loss: 0.2080 - val_accuracy: 0.9337\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3497 - accuracy: 0.8719 - val_loss: 0.2495 - val_accuracy: 0.9250\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3329 - accuracy: 0.8771 - val_loss: 0.2165 - val_accuracy: 0.9334\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 91s 348ms/step - loss: 0.3318 - accuracy: 0.8742 - val_loss: 0.2597 - val_accuracy: 0.9106\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3388 - accuracy: 0.8755 - val_loss: 0.2970 - val_accuracy: 0.9079\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3274 - accuracy: 0.8786 - val_loss: 0.2465 - val_accuracy: 0.9229\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 3\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 80s 307ms/step - loss: 2.1066 - accuracy: 0.5526 - val_loss: 0.7125 - val_accuracy: 0.7241: 43s - lo - ETA: 37s - loss: 3.7621 - accuracy: 0.444 - ETA: 37s - loss: 3.7367 - accuracy: 0.446 - ETA: 37s - loss: 3.7118 - accuracy: 0 - ETA: 36s - loss: 3.5951 - accuracy: 0 - ETA: 35s - loss: 3.4895 - accuracy: - ETA: 33s - loss: 3.3569 - accura - ETA: 32s - loss: 3.1935 - accuracy: 0 - ETA: 31s - loss: 3.1215 - accuracy: 0. - ETA: 30s - loss: 3.0680 - accuracy: 0.48 - ETA: 29s - loss: 3.0425 - accuracy: - ETA: 28s - loss: 2 - ETA: 23s - loss: 2.7257  - ETA: 6s - loss: 2.2194 -  - ETA: 4s - loss: 2 - ETA: 2s - loss: 2.1462 - ac - ETA: 0s - loss: 2.1228 - accuracy:  - ETA: 0s - loss: 2.1130 - accuracy: 0.\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.8591 - accuracy: 0.6754 - val_loss: 0.6593 - val_accuracy: 0.7342\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7796 - accuracy: 0.7085 - val_loss: 0.6558 - val_accuracy: 0.7473ETA: 26s - loss: 0.7887 - accuracy: 0. - ETA: 25s - loss: 0 - ETA: 1s - loss: 0.7\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7213 - accuracy: 0.7308 - val_loss: 0.5538 - val_accuracy: 0.7862\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7169 - accuracy: 0.7410 - val_loss: 0.6187 - val_accuracy: 0.7615: 49s - loss: 0.7698 - ac - ETA: 46s - loss: 0.7576 - accu - ETA: 44s - loss: 0.7550 - accura - ETA: 4 - ETA: 4s - - ETA: 1s - loss: 0.7170 - \n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7133 - accuracy: 0.7435 - val_loss: 0.6185 - val_accuracy: 0.74448s - - ETA: 22s - loss: 0.7222 - accura - ETA:  - ETA: 13s - lo\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6629 - accuracy: 0.7633 - val_loss: 0.7063 - val_accuracy: 0.7073 E\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6656 - accuracy: 0.7611 - val_loss: 0.5568 - val_accuracy: 0.7771: 0.667 - ETA: 13s - loss: 0.6663 - accuracy: - ETA: 2s - loss: 0\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6680 - accuracy: 0.7594 - val_loss: 0.4687 - val_accuracy: 0.81597s - loss: 0.6941  - ETA: 34s - loss: 0.6862 - accuracy: - ETA: 32s - loss: 0.6837 - accuracy: 0.748 - ETA: 32s - loss: 0.6833 - accuracy - ETA: 31s - loss: 0.6808  - ETA: 27s - loss: 0.6774 - accuracy: - ETA: 26s - loss: 0.676 - ETA: 22s - loss: 0.6730 - accuracy: - ETA: 20s - loss: 0.6726 - accuracy: 0. - ETA: 19s - loss: 0.6723 - a - ETA: 16s - loss: 0.6715 - accu - ETA: 14s - loss: 0.6711 - - ETA: 1 - ETA: 6s - - ETA: 3s - loss: 0.6688 - accuracy:  - ETA: 3s\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6640 - accuracy: 0.7620 - val_loss: 0.4589 - val_accuracy: 0.8313\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6620 - accuracy: 0.7653 - val_loss: 0.5318 - val_accuracy: 0.78346586 - accuracy: 0 - ETA: 32s - loss: 0.6586 - accuracy: - ETA: 30s - loss: 0.6587 - accurac - ETA: 29s - - - ETA: 3s - loss: 0.662 - ETA: 1s - loss: 0.6622 - ac\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6419 - accuracy: 0.7715 - val_loss: 0.5133 - val_accuracy: 0.8040\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6337 - accuracy: 0.7662 - val_loss: 0.6197 - val_accuracy: 0.7539TA: 33s - loss: 0.6347  - ETA: 29s - loss: 0 - ETA: 24s - loss: 0.6331 - a - ETA: 21s - loss: 0.6331 - accuracy:  - ETA: 20s - loss: 0.6331 - accurac - ETA: 18s - loss: 0.6331 - - ET\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6272 - accuracy: 0.7675 - val_loss: 0.4787 - val_accuracy: 0.818312s - l - ETA: 3s - loss: 0.6278 - accuracy: 0. - ETA: 3s - loss: 0.6278 - accuracy:  - ETA: 2s - l\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6318 - accuracy: 0.7728 - val_loss: 0.4572 - val_accuracy: 0.8245s: 0.6126 - accuracy: 0 - ETA: 41s - loss: 0.6 -  - ETA: 28s - loss: 0.6226 - accuracy: 0 - ETA: 27s - loss: 0.6233 - accurac - ETA: 2 - ETA: 0s - loss: 0.6318 - accuracy\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6125 - accuracy: 0.7727 - val_loss: 0.5382 - val_accuracy: 0.7922\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 80s 309ms/step - loss: 0.6285 - accuracy: 0.7714 - val_loss: 0.4595 - val_accuracy: 0.8252 loss:  - ETA: 2s - l\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6143 - accuracy: 0.7771 - val_loss: 0.4794 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5971 - accuracy: 0.7896 - val_loss: 0.5285 - val_accuracy: 0.7917ETA: 38s - loss: 0.5855 - acc - ETA: 36s - loss: 0.5870 - accur - ETA: 34s - loss: 0. - ETA: 20s - loss: 0.5895 - ac - ETA: 17s - loss: 0.5911 - accuracy: 0.790 -  - ETA: 0s - loss: 0.5969 - accura\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6087 - accuracy: 0.7890 - val_loss: 0.4722 - val_accuracy: 0.8218\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5885 - accuracy: 0.7794 - val_loss: 0.4634 - val_accuracy: 0.8215ETA: 28s - loss - E - ETA: 7s - - ETA: 4s - loss: 0.5864 -  - ETA: 3s - loss: 0.5871 - ac - ETA: 1s - loss: 0.587\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6283 - accuracy: 0.7707 - val_loss: 0.3989 - val_accuracy: 0.86180.6283 - accuracy: 0.\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5859 - accuracy: 0.7841 - val_loss: 0.5555 - val_accuracy: 0.7885ss: 0.5841 - accuracy: 0 - ETA: 18s - loss:  - ETA: 13s - loss: 0.5843 - accuracy: 0 - ETA: 12s - loss: 0.5844 - accuracy: 0 - ETA: 11s - loss: 0.5846  - ETA: 4s - loss: 0.5852 - accuracy - ETA\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5845 - accuracy: 0.7858 - val_loss: 0.4831 - val_accuracy: 0.8196: 29s - loss: 0.5 - ETA: 25s - loss:  - ETA: 20s - loss: 0.5911 - ETA: 16s - los - ETA: 11s - loss: 0.587\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6327 - accuracy: 0.7753 - val_loss: 0.4209 - val_accuracy: 0.8444 accu - E\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5548 - accuracy: 0.7972 - val_loss: 0.4827 - val_accuracy: 0.8140s - loss: 0.4 - ETA: 40s - loss: - ETA: 35s - loss: 0.5296 - accuracy: - ETA: 34s - loss - ETA: 19 - ETA: 2s - loss:\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5914 - accuracy: 0.7871 - val_loss: 0.4486 - val_accuracy: 0.8291 23\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5934 - accuracy: 0.7926 - val_loss: 0.5135 - val_accuracy: 0.80797s - loss: 0.5920 - ETA: 13s - loss: 0.5927 - accuracy - ETA: 12s - loss: 0.5 - ETA: 8s - E - ETA: 1s - loss: 0.5933 - accuracy: 0. - ETA: 1s - loss: 0.5933 - ac\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5769 - accuracy: 0.7870 - val_loss: 0.4722 - val_accuracy: 0.8144ETA: 14s - loss: 0. - ETA: 9s - loss: 0.5752 - accuracy:  - ETA: 9s - loss: 0.575 - ETA: 2s - los\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5887 - accuracy: 0.7793 - val_loss: 0.4508 - val_accuracy: 0.8244loss: 0.6068  - ETA: 35s - loss: 0.5960 - accur - ETA: 33s - loss: 0.5940 - accuracy: 0.77 - ETA: 32s - loss - ETA: 27s - loss: 0. - ETA: 22s - loss: 0.5887 - accuracy: 0 - ETA: 21s - loss: 0.5886 - accura - ETA: 19s - lo - ETA: 13s - loss: 0.5886 - accu - ETA: 11s - loss: 0.58\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5939 - accuracy: 0.7807 - val_loss: 0.4415 - val_accuracy: 0.8349\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5815 - accuracy: 0.7904 - val_loss: 0.5092 - val_accuracy: 0.8032: 41s - loss: 0.5828 - accurac - ETA: 39s - loss: 0.5836 - acc - ETA: 37s - loss: 0.5827 - ac\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.8775 - accuracy: 0.6858 - val_loss: 0.5001 - val_accuracy: 0.8238\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.5915 - accuracy: 0.7817 - val_loss: 0.2940 - val_accuracy: 0.9098\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.5100 - accuracy: 0.8063 - val_loss: 0.2930 - val_accuracy: 0.9090\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4825 - accuracy: 0.8130 - val_loss: 0.3247 - val_accuracy: 0.8910\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4623 - accuracy: 0.8160 - val_loss: 0.2357 - val_accuracy: 0.9238\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4382 - accuracy: 0.8403 - val_loss: 0.2419 - val_accuracy: 0.9233\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.4132 - accuracy: 0.8503 - val_loss: 0.2161 - val_accuracy: 0.9376\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3933 - accuracy: 0.8511 - val_loss: 0.2062 - val_accuracy: 0.9359\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4036 - accuracy: 0.8499 - val_loss: 0.2114 - val_accuracy: 0.9296\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3671 - accuracy: 0.8626 - val_loss: 0.1927 - val_accuracy: 0.9399\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 90s 345ms/step - loss: 0.3814 - accuracy: 0.8615 - val_loss: 0.2179 - val_accuracy: 0.9294\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3499 - accuracy: 0.8658 - val_loss: 0.1849 - val_accuracy: 0.9397\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3619 - accuracy: 0.8707 - val_loss: 0.1955 - val_accuracy: 0.9421\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3398 - accuracy: 0.8681 - val_loss: 0.2112 - val_accuracy: 0.9300\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3354 - accuracy: 0.8730 - val_loss: 0.2346 - val_accuracy: 0.9304\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3336 - accuracy: 0.8736 - val_loss: 0.1838 - val_accuracy: 0.9432\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3452 - accuracy: 0.8734 - val_loss: 0.1930 - val_accuracy: 0.9396\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3321 - accuracy: 0.8760 - val_loss: 0.1949 - val_accuracy: 0.9417\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3325 - accuracy: 0.8747 - val_loss: 0.2090 - val_accuracy: 0.9396\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3315 - accuracy: 0.8801 - val_loss: 0.2432 - val_accuracy: 0.9256\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3384 - accuracy: 0.8717 - val_loss: 0.2310 - val_accuracy: 0.9257\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3023 - accuracy: 0.8850 - val_loss: 0.1840 - val_accuracy: 0.9398\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2996 - accuracy: 0.8865 - val_loss: 0.1800 - val_accuracy: 0.9439\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3244 - accuracy: 0.8787 - val_loss: 0.1919 - val_accuracy: 0.9352\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3115 - accuracy: 0.8965 - val_loss: 0.1851 - val_accuracy: 0.9427\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2909 - accuracy: 0.8908 - val_loss: 0.1871 - val_accuracy: 0.9401\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3171 - accuracy: 0.8775 - val_loss: 0.2241 - val_accuracy: 0.9362\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2991 - accuracy: 0.8871 - val_loss: 0.1816 - val_accuracy: 0.9499\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2682 - accuracy: 0.9006 - val_loss: 0.2180 - val_accuracy: 0.9405\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.2885 - accuracy: 0.8971 - val_loss: 0.2147 - val_accuracy: 0.9396\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.2896 - accuracy: 0.8952 - val_loss: 0.1984 - val_accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.2672 - accuracy: 0.9033 - val_loss: 0.1987 - val_accuracy: 0.9491\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.2967 - accuracy: 0.8931 - val_loss: 0.2255 - val_accuracy: 0.9467\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n",
      "Execution for batch: 4\n",
      "Computing weights for the classes.\n",
      "Training the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 2.5871 - accuracy: 0.5614 - val_loss: 1.0584 - val_accuracy: 0.5798TA: 40s - loss: 5.4747  - ETA: 36s - loss: 4.7483 -  - ETA: 33s - loss: 4.3016 -  - ETA: 30s - loss: 3.9662  - ETA: 27s - loss: 3.6726 - - ETA: 23s - loss: 3.4509 - accuracy: - ETA: 22s - loss: 3.3715 - a - ETA: 19s - loss: 3.2191 - accuracy: 0.536 - ETA: 19s - loss: 3.2097 - accuracy - ETA: 17s - loss: 3.1377 - accuracy - ETA - ETA: 9s - loss: 2.8280  - ETA: 7s -\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 80s 307ms/step - loss: 0.9668 - accuracy: 0.6591 - val_loss: 0.7488 - val_accuracy: 0.76562s - l\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.8775 - accuracy: 0.6997 - val_loss: 0.7031 - val_accuracy: 0.7755A: 44 - ETA: 37s - loss: 0.8697  - ETA: 33s - loss: 0.8717 - accu - ETA: 31s - loss: 0.874 - ETA: 0s - loss: 0.8775 - accuracy\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.8619 - accuracy: 0.6986 - val_loss: 0.6437 - val_accuracy: 0.7825- loss: 0 - ETA: 42s - loss: 0.8710 - accuracy: 0.6 - ETA: 42s - loss:  - ETA: 1s - loss: 0.8624 - \n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7814 - accuracy: 0.7205 - val_loss: 0.6104 - val_accuracy: 0.79395s - loss: 0.7726 - accuracy:  - ETA: 24s - loss: 0.77 - ETA: 20s - loss: 0.7748 - accura - ETA: 18s - los - ETA: 12s  - ETA: 8s - loss: 0.7 - ETA: 5s - loss: - ETA: \n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7585 - accuracy: 0.7316 - val_loss: 0.6598 - val_accuracy: 0.7588- ETA: 19s - loss:  - ETA: \n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7741 - accuracy: 0.7223 - val_loss: 0.5789 - val_accuracy: 0.80049s - loss: 0.75 - ETA: 45s - loss: 0.8000 - accuracy: 0 - ET - ETA: 27s - loss: 0.7844 - accuracy: 0.7 - ETA: 27s - loss: 0.7844 - accuracy: 0.7 - ETA: 26s - loss: 0.7844 - accurac - ETA: 24s - loss: 0.784 - ETA: 20s - loss: 0.78 - ETA: 16s - loss: 0.7813 - accuracy: 0. - ETA: 15s - loss: 0.7810 - ac - ETA: 12s - loss: 0.7798 - accuracy: 0.71 - ETA: 12s - loss: 0.7796 - accuracy: 0.7 - ETA: 11s - loss: 0.7794 - accuracy: 0.7 - ETA: 11s - loss: 0.7792 - - ETA: 0s - loss: 0.7742 - accuracy: 0.\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7377 - accuracy: 0.7300 - val_loss: 0.6174 - val_accuracy: 0.7516\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.7204 - accuracy: 0.7379 - val_loss: 0.6016 - val_accuracy: 0.7818\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 80s 307ms/step - loss: 0.7449 - accuracy: 0.7363 - val_loss: 0.5928 - val_accuracy: 0.7692accura - ETA: 3 - ETA: 27s - loss: 0.7472 -  - ETA: 24s - loss: 0.7491 - - ETA: 21s - loss: 0.7500 - accuracy: 0.73 - ETA: 20s - loss: 0.7\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 80s 307ms/step - loss: 0.6897 - accuracy: 0.7477 - val_loss: 0.6745 - val_accuracy: 0.7209ss: 0.65 - ETA: 38s - loss: 0.6621 - accuracy:   - ETA: 28s - loss: 0.6783 - a - ETA: 16s - loss: - ETA: 11s - l - ETA: 3s\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6989 - accuracy: 0.7435 - val_loss: 0.5841 - val_accuracy: 0.7756ETA: 30s - los - ETA: 2 - ETA: 0s - loss: 0.6990 - accuracy\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6743 - accuracy: 0.7522 - val_loss: 0.5776 - val_accuracy: 0.78100.6613 - accurac - ETA: 35s - loss: 0.6624 - a - ETA: 32 - ETA: 26s - loss: 0.6706 - accuracy: 0. \n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6822 - accuracy: 0.7476 - val_loss: 0.5183 - val_accuracy: 0.8151- lo - ETA: 43s - loss: 0.6823 - accu - ETA: 41s - loss: 0.6867 - accura - ETA: 3 - ETA: 23s - loss: 0. - ETA: 5s - loss: 0.6 - ETA: 3s\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6697 - accuracy: 0.7556 - val_loss: 0.5283 - val_accuracy: 0.7962y: 0 - ETA: 35s - loss: 0.6769  - ETA: 22s - loss: 0.6773 - accur - ETA: 20s - loss:  - ETA: 15s - loss:  - ETA: 10s - loss: 0.6729 \n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6689 - accuracy: 0.7555 - val_loss: 0.5765 - val_accuracy: 0.7765loss: 0.6543 - accuracy: 0.7 - ETA: 38s - loss: 0.6547 - accuracy: 0 - ETA: 37s - loss: 0.6550 - accuracy:  - - ETA: 27s - loss: 0.6635 - accuracy: - ETA: 25s - loss: 0.6643 -  - ETA: 22s - loss: 0.6657 - accur - ETA: 20s - loss: 0.6661 - accuracy: 0.75 - ETA: 20s - loss: 0 - ETA\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6620 - accuracy: 0.7582 - val_loss: 0.5086 - val_accuracy: 0.8159.6602 - accuracy: 0 - ETA: 46s - loss: - ETA: 41s - ETA: 25s - loss: 0.6690 - accuracy: 0.7 - ETA: 25s - loss: 0.6691 - ETA: 21s - loss: \n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 81s 308ms/step - loss: 0.6380 - accuracy: 0.7752 - val_loss: 0.5540 - val_accuracy: 0.7980 47s - loss: 0.6032 - accuracy: 0 - ETA: 46s - loss: 0.5976 - accuracy: 0.7 - ETA: 45s - loss: 0.5951 - ETA: 41s - - ETA: 35s - loss: 0.6 - ETA: 31s - loss - ETA: 25s - loss: 0.6223 - ac - ETA: 23s - loss:  - ETA: 18s - loss: 0.6301 - accura - ETA: 16s  - ETA: 0s - loss: 0.6377 - accura\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6475 - accuracy: 0.7652 - val_loss: 0.6256 - val_accuracy: 0.7442\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6782 - accuracy: 0.7541 - val_loss: 0.5009 - val_accuracy: 0.8179\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6444 - accuracy: 0.7734 - val_loss: 0.5126 - val_accuracy: 0.80928 - accu - ETA: 35s - loss: - ETA: 30s - loss:\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6568 - accuracy: 0.7593 - val_loss: 0.4942 - val_accuracy: 0.8206\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6051 - accuracy: 0.7848 - val_loss: 0.6435 - val_accuracy: 0.7411s - loss: 0 - ETA: 44s - loss: 0.5368 - accuracy: - ETA: 43s - loss: 0.5442 - accura - ETA: 4\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6376 - accuracy: 0.7631 - val_loss: 0.4981 - val_accuracy: 0.8092: 10s - loss: 0.6380 - a\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6150 - accuracy: 0.7833 - val_loss: 0.6393 - val_accuracy: 0.7509ss: 0.6028 - accuracy - ETA: 27s - loss: 0.6045 - accuracy - ETA: 26s - loss: 0.6063 -  - ETA: 23s - loss: 0.6091 - accu - ETA: 20s - loss: 0.6104  - ETA: 17s - loss: 0.6119 - accu - ETA: \n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6133 - accuracy: 0.7754 - val_loss: 0.5147 - val_accuracy: 0.8039\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5960 - accuracy: 0.7938 - val_loss: 0.6051 - val_accuracy: 0.7662\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6103 - accuracy: 0.7782 - val_loss: 0.4763 - val_accuracy: 0.8253 - loss: 0.5667 - accuracy:  - ETA: 0s - loss: 0.6101 - accuracy\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6159 - accuracy: 0.7797 - val_loss: 0.4997 - val_accuracy: 0.8163 loss: 0.5984 - accuracy: - ETA: - ETA: 19s - - ETA: 7s - l\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6145 - accuracy: 0.7842 - val_loss: 0.6165 - val_accuracy: 0.75610.5894 - accuracy: 0 - ETA: 34s - loss: 0.5915 - accura - ETA: 32s - loss: 0.5957 - accuracy:  -  - ETA: 22s - loss: 0.6062 - accuracy: 0 - ETA: 21s - loss: 0.6068 - a - E - ETA: 10s - loss: 0.6114 - accuracy: 0.78 - ETA: 10s - loss: 0.6116 - accu - E - ETA: 0s - loss: 0.6143 - accuracy\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6031 - accuracy: 0.7817 - val_loss: 0.4609 - val_accuracy: 0.8334: 40s - loss: 0.5 - ETA: 36s - loss: 0.5778 - a - ETA: 33s - loss: 0.5831 - accuracy: 0 - ETA:  - ETA: 4s - loss: 0.6 - ETA: 1s - loss: 0.6\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6017 - accuracy: 0.7809 - val_loss: 0.4583 - val_accuracy: 0.83215716 - accu - ETA: 32s - loss: 0.5780 - accuracy: 0.78 - ETA: 32s - loss: 0.5791 - accuracy: 0.7 - ETA: 31s - loss: 0.5806 - accur - ETA: - ETA: 21s - loss: 0.5959  - ETA: 18s - loss: 0.5982 - acc - ETA: 15s - loss: 0.5994 - a - ETA: 12s - loss: 0.6002 - accuracy: 0.78 - ETA: 12s - loss: \n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6233 - accuracy: 0.7759 - val_loss: 0.5880 - val_accuracy: 0.7800: 49s - loss: 0.5441 - a - ETA: 46s - loss: 0.5818 - ac - ETA: 43s - los - ETA: 38s - loss: 0.6014 - accura - ETA: 36s - loss: 0.6035 - a - ETA: 33s - loss: 0.6085 - E - ETA: 2s - loss: 0\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6232 - accuracy: 0.7760 - val_loss: 0.4391 - val_accuracy: 0.84692s - loss: 0.6002 - accura - ETA: 21s - loss: 0.6173 - accuracy: 0 - ETA: 20s - loss: 0.6180 - accura - ETA: 0s - loss: 0.6230 - accuracy:  - ETA: 0s - loss: 0.6231 - accuracy: 0.\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6350 - accuracy: 0.7655 - val_loss: 0.4855 - val_accuracy: 0.8237ccuracy - ETA: 34s - loss: 0.650 - ETA: 2s - los\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.5921 - accuracy: 0.7863 - val_loss: 0.5747 - val_accuracy: 0.7787 0.5631 -  - ETA: 42s - loss: 0.5620 - accur - ETA: 22s - loss: 0.5822 - accuracy: - ETA: 21s - loss: 0.58 - ETA:  - ETA: 0s - loss: 0.5918 - accura\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6028 - accuracy: 0.7907 - val_loss: 0.5499 - val_accuracy: 0.7763curacy: 0. - ETA: 44s - loss: 0.56 - ETA: 40s - loss: 0 - ETA: 35s - loss: 0.5729 - accu - ETA: 33s - loss: 0. - ETA: 28s - loss: 0 - ETA: 24s - loss: 0.5 - ETA: 19s - loss: 0.599 - ETA: 3s - loss: 0.6028 - accura - ETA: 2s -\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 81s 309ms/step - loss: 0.6036 - accuracy: 0.7862 - val_loss: 0.5850 - val_accuracy: 0.761324s - l - E - ETA: 1s - loss: 0.6033 - ac\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6037 - accuracy: 0.7851 - val_loss: 0.5745 - val_accuracy: 0.7718\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5970 - accuracy: 0.7878 - val_loss: 0.5140 - val_accuracy: 0.8098775 - accuracy: - ETA: 34s - loss: 0.5 - ETA: 30s - l - ETA: 24s - loss: 0.5920 - accuracy: - ETA - ETA: 7s - loss: 0.5968 -  - ETA: 6s - loss: 0.5969 -  - ETA: 4s - loss: 0.5969 - accura - E\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6182 - accuracy: 0.7704 - val_loss: 0.4388 - val_accuracy: 0.8415230 - accura - ETA: 16s - lo - ETA: 10s - loss: 0.6211 \n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5932 - accuracy: 0.7784 - val_loss: 0.4692 - val_accuracy: 0.8277\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5982 - accuracy: 0.7852 - val_loss: 0.4514 - val_accuracy: 0.8330s - loss: 0.5982 - accuracy: \n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5681 - accuracy: 0.7924 - val_loss: 0.4629 - val_accuracy: 0.8377\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5997 - accuracy: 0.7880 - val_loss: 0.5653 - val_accuracy: 0.7878\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6156 - accuracy: 0.7831 - val_loss: 0.5217 - val_accuracy: 0.7998s: 0.6207 - ETA: 2 - ETA: 13s - loss: 0.6193 - accurac - ETA: 12s - loss: 0.\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5792 - accuracy: 0.7948 - val_loss: 0.6281 - val_accuracy: 0.7656- loss: 0.509 - ETA: 44s - loss: 0.5410 -  - ETA: 41s - loss: 0.5550 -  - ETA: 37s - loss: 0. - ETA: 33s - loss: 0.5 - ETA: 20s - loss: 0.5781 \n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6006 - accuracy: 0.7808 - val_loss: 0.4578 - val_accuracy: 0.8293TA: 36s - loss: 0.5915 - ac - ETA: 33s - loss: 0.5922 - accura - ETA: 13s\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.6069 - accuracy: 0.7793 - val_loss: 0.5392 - val_accuracy: 0.7962\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5941 - accuracy: 0.7873 - val_loss: 0.5772 - val_accuracy: 0.7729loss: 0.6016 -  - - E - ETA: 5s - l - ETA: 2s - loss: 0.5946 - accura - ETA: 1s - loss: 0.5943 - accuracy: 0.78 - ETA: 1s - loss: 0.5943 - accuracy: 0.78 - ETA: 1s - loss: 0.5943 - ac\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 80s 308ms/step - loss: 0.5926 - accuracy: 0.7799 - val_loss: 0.5455 - val_accuracy: 0.795222s - loss: 0.5872 - accuracy - ETA: 21s - loss: 0.5884 -  - ETA: 18s - loss: 0.5900 - accuracy: 0. - ETA: 17s - loss: 0.5906 - accu - ETA: 14s - loss: 0.5916 - accurac - ETA: 1 - ETA: 7s - loss: 0.5925 - ac - ETA: 6s - los - E\n",
      "Fine-tuning the classifier.\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.9105 - accuracy: 0.6967 - val_loss: 0.5091 - val_accuracy: 0.8158\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.6111 - accuracy: 0.7847 - val_loss: 0.3818 - val_accuracy: 0.8745\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.5559 - accuracy: 0.8066 - val_loss: 0.3137 - val_accuracy: 0.8940\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4936 - accuracy: 0.8211 - val_loss: 0.4406 - val_accuracy: 0.8531\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4502 - accuracy: 0.8418 - val_loss: 0.3598 - val_accuracy: 0.8857\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4506 - accuracy: 0.8403 - val_loss: 0.2920 - val_accuracy: 0.9047\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4492 - accuracy: 0.8365 - val_loss: 0.2454 - val_accuracy: 0.9241\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4221 - accuracy: 0.8511 - val_loss: 0.3276 - val_accuracy: 0.8979\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4095 - accuracy: 0.8571 - val_loss: 0.2492 - val_accuracy: 0.9257\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.4024 - accuracy: 0.8555 - val_loss: 0.3117 - val_accuracy: 0.8977\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3753 - accuracy: 0.8641 - val_loss: 0.2334 - val_accuracy: 0.9277\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 90s 345ms/step - loss: 0.3862 - accuracy: 0.8628 - val_loss: 0.3287 - val_accuracy: 0.8862\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3941 - accuracy: 0.8590 - val_loss: 0.2304 - val_accuracy: 0.9376\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3684 - accuracy: 0.8643 - val_loss: 0.2520 - val_accuracy: 0.9235\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3600 - accuracy: 0.8708 - val_loss: 0.3257 - val_accuracy: 0.8832\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3463 - accuracy: 0.8764 - val_loss: 0.2942 - val_accuracy: 0.9073\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3310 - accuracy: 0.8797 - val_loss: 0.2132 - val_accuracy: 0.9355\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3434 - accuracy: 0.8819 - val_loss: 0.3061 - val_accuracy: 0.9052\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3426 - accuracy: 0.8684 - val_loss: 0.2068 - val_accuracy: 0.9392\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3203 - accuracy: 0.8820 - val_loss: 0.2227 - val_accuracy: 0.9378\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 91s 347ms/step - loss: 0.3384 - accuracy: 0.8792 - val_loss: 0.2081 - val_accuracy: 0.9445\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3205 - accuracy: 0.8821 - val_loss: 0.2946 - val_accuracy: 0.9170\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 90s 347ms/step - loss: 0.3248 - accuracy: 0.8819 - val_loss: 0.2853 - val_accuracy: 0.9182\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3257 - accuracy: 0.8796 - val_loss: 0.2671 - val_accuracy: 0.9100\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3221 - accuracy: 0.8861 - val_loss: 0.2272 - val_accuracy: 0.9370\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3189 - accuracy: 0.8824 - val_loss: 0.2431 - val_accuracy: 0.9311\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2938 - accuracy: 0.8947 - val_loss: 0.2872 - val_accuracy: 0.9226\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.2957 - accuracy: 0.8957 - val_loss: 0.2287 - val_accuracy: 0.9331\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 90s 346ms/step - loss: 0.3043 - accuracy: 0.8883 - val_loss: 0.2432 - val_accuracy: 0.9419\n",
      "Model Evaluation.\n",
      "Saving artifacts.\n",
      "Saving Projections\n",
      "Saving Saliency Maps\n"
     ]
    }
   ],
   "source": [
    "data_fractions_list = [10] # 1%, 5%, 10%\n",
    "for fraction in data_fractions_list:\n",
    "#     clear_output(wait=True)\n",
    "    get_results_for_data_fraction(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Fraction</th>\n",
       "      <th>Batch_Number</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992769</td>\n",
       "      <td>0.992849</td>\n",
       "      <td>0.992769</td>\n",
       "      <td>0.992768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994835</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>0.994835</td>\n",
       "      <td>0.994822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984504</td>\n",
       "      <td>0.984576</td>\n",
       "      <td>0.984504</td>\n",
       "      <td>0.984504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984504</td>\n",
       "      <td>0.985409</td>\n",
       "      <td>0.984504</td>\n",
       "      <td>0.984550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.984001</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.983442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Fraction  Batch_Number  Accuracy  Precision    Recall  F1_Score\n",
       "0             10             0  0.992769   0.992849  0.992769  0.992768\n",
       "1             10             1  0.994835   0.994890  0.994835  0.994822\n",
       "2             10             2  0.984504   0.984576  0.984504  0.984504\n",
       "3             10             3  0.984504   0.985409  0.984504  0.984550\n",
       "4             10             4  0.983471   0.984001  0.983471  0.983442"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Number</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Fraction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.988345</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.988017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Batch_Number  Accuracy  Precision    Recall  F1_Score\n",
       "Data_Fraction                                                       \n",
       "10                        2  0.988017   0.988345  0.988017  0.988017"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_store.groupby('Data_Fraction').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina_env",
   "language": "python",
   "name": "retina_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
