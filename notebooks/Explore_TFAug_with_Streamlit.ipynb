{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFAug-Create-streamlit-app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoopsanka/retinal_oct/blob/main/notebooks/Explore_TFAug_with_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWmc_s2ezvU0"
      },
      "source": [
        "# [Run streamlit app from a Google Colab Notebook](https://discuss.streamlit.io/t/free-streamlit-dev-environment-through-colaboratory/2778/12)\n",
        "\n",
        "> andfanilo\n",
        ">Just discovered that npm is available on Colab :exploding_head: so you can use any node package in Colab, which means localtunnel 3 to expose your Streamlit app to the world (until the notebook or the localtunnel server get shut down at least XD)\n",
        "\n",
        ">so you can run the following 4 Colab cells, and get the exposed URL at the end. :\n",
        "```python\n",
        "!pip install streamlit\n",
        "!npm install localtunnel\n",
        "!streamlit run app.py &>/dev/null&\n",
        "!npx localtunnel --port 8501\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlYkCQ9vFiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3456e4a1-a6fc-4f89-bef1-57fe39d7757d"
      },
      "source": [
        "!pip install streamlit\r\n",
        "!npm install localtunnel\r\n",
        "!streamlit run app.py &>/dev/null&\r\n",
        "!npx localtunnel --port 8501"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.5MB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5MB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 17.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 58.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 60.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.4.2 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzvl_5Cv8HeX"
      },
      "source": [
        "Reset the execution environment after streamlit installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o47JAGm_w1Fo",
        "outputId": "2856d86f-4b42-475f-90bf-91677b6a4413"
      },
      "source": [
        "%%writefile img_aug.py\r\n",
        "import streamlit as st\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import functools\r\n",
        "\r\n",
        "\r\n",
        "# coding=utf-8\r\n",
        "# Copyright 2020 The SimCLR Authors.\r\n",
        "#\r\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "# you may not use this file except in compliance with the License.\r\n",
        "# You may obtain a copy of the License at\r\n",
        "#\r\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "#\r\n",
        "# Unless required by applicable law or agreed to in writing, software\r\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "# See the License for the specific simclr governing permissions and\r\n",
        "# limitations under the License.\r\n",
        "# ==============================================================================\r\n",
        "\"\"\"Data preprocessing and augmentation.\"\"\"\r\n",
        "\r\n",
        "CROP_PROPORTION = 0.875  # Standard for ImageNet.\r\n",
        "def random_apply(func, p, x):\r\n",
        "  \"\"\"Randomly apply function func to x with probability p.\"\"\"\r\n",
        "  return tf.cond(\r\n",
        "      tf.less(\r\n",
        "          tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\r\n",
        "          tf.cast(p, tf.float32)), lambda: func(x), lambda: x)\r\n",
        "\r\n",
        "\r\n",
        "def random_brightness(image, max_delta, impl='simclrv2'):\r\n",
        "  \"\"\"A multiplicative vs additive change of brightness.\"\"\"\r\n",
        "  if impl == 'simclrv2':\r\n",
        "    factor = tf.random.uniform([], tf.maximum(1.0 - max_delta, 0),\r\n",
        "                               1.0 + max_delta)\r\n",
        "    image = image * factor\r\n",
        "  elif impl == 'simclrv1':\r\n",
        "    image = tf.image.random_brightness(image, max_delta=max_delta)\r\n",
        "  else:\r\n",
        "    raise ValueError('Unknown impl {} for random brightness.'.format(impl))\r\n",
        "  return image\r\n",
        "\r\n",
        "\r\n",
        "def to_grayscale(image, keep_channels=True):\r\n",
        "  image = tf.image.rgb_to_grayscale(image)\r\n",
        "  if keep_channels:\r\n",
        "    image = tf.tile(image, [1, 1, 3])\r\n",
        "  return image\r\n",
        "\r\n",
        "\r\n",
        "def color_jitter(image, strength, random_order=True, impl='simclrv2'):\r\n",
        "  \"\"\"Distorts the color of the image.\r\n",
        "  Args:\r\n",
        "    image: The input image tensor.\r\n",
        "    strength: the floating number for the strength of the color augmentation.\r\n",
        "    random_order: A bool, specifying whether to randomize the jittering order.\r\n",
        "    impl: 'simclrv1' or 'simclrv2'.  Whether to use simclrv1 or simclrv2's\r\n",
        "        version of random brightness.\r\n",
        "  Returns:\r\n",
        "    The distorted image tensor.\r\n",
        "  \"\"\"\r\n",
        "  brightness = 0.8 * strength\r\n",
        "  contrast = 0.8 * strength\r\n",
        "  saturation = 0.8 * strength\r\n",
        "  hue = 0.2 * strength\r\n",
        "  if random_order:\r\n",
        "    return color_jitter_rand(\r\n",
        "        image, brightness, contrast, saturation, hue, impl=impl)\r\n",
        "  else:\r\n",
        "    return color_jitter_nonrand(\r\n",
        "        image, brightness, contrast, saturation, hue, impl=impl)\r\n",
        "\r\n",
        "\r\n",
        "def color_jitter_nonrand(image,\r\n",
        "                         brightness=0,\r\n",
        "                         contrast=0,\r\n",
        "                         saturation=0,\r\n",
        "                         hue=0,\r\n",
        "                         impl='simclrv2'):\r\n",
        "  \"\"\"Distorts the color of the image (jittering order is fixed).\r\n",
        "  Args:\r\n",
        "    image: The input image tensor.\r\n",
        "    brightness: A float, specifying the brightness for color jitter.\r\n",
        "    contrast: A float, specifying the contrast for color jitter.\r\n",
        "    saturation: A float, specifying the saturation for color jitter.\r\n",
        "    hue: A float, specifying the hue for color jitter.\r\n",
        "    impl: 'simclrv1' or 'simclrv2'.  Whether to use simclrv1 or simclrv2's\r\n",
        "        version of random brightness.\r\n",
        "  Returns:\r\n",
        "    The distorted image tensor.\r\n",
        "  \"\"\"\r\n",
        "  with tf.name_scope('distort_color'):\r\n",
        "    def apply_transform(i, x, brightness, contrast, saturation, hue):\r\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\r\n",
        "      if brightness != 0 and i == 0:\r\n",
        "        x = random_brightness(x, max_delta=brightness, impl=impl)\r\n",
        "      elif contrast != 0 and i == 1:\r\n",
        "        x = tf.image.random_contrast(\r\n",
        "            x, lower=1-contrast, upper=1+contrast)\r\n",
        "      elif saturation != 0 and i == 2:\r\n",
        "        x = tf.image.random_saturation(\r\n",
        "            x, lower=1-saturation, upper=1+saturation)\r\n",
        "      elif hue != 0:\r\n",
        "        x = tf.image.random_hue(x, max_delta=hue)\r\n",
        "      return x\r\n",
        "\r\n",
        "    for i in range(4):\r\n",
        "      image = apply_transform(i, image, brightness, contrast, saturation, hue)\r\n",
        "      # image = tf.clip_by_value(image, 0., 1.)\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def color_jitter_rand(image,\r\n",
        "                      brightness=0,\r\n",
        "                      contrast=0,\r\n",
        "                      saturation=0,\r\n",
        "                      hue=0,\r\n",
        "                      impl='simclrv2'):\r\n",
        "  \"\"\"Distorts the color of the image (jittering order is random).\r\n",
        "  Args:\r\n",
        "    image: The input image tensor.\r\n",
        "    brightness: A float, specifying the brightness for color jitter.\r\n",
        "    contrast: A float, specifying the contrast for color jitter.\r\n",
        "    saturation: A float, specifying the saturation for color jitter.\r\n",
        "    hue: A float, specifying the hue for color jitter.\r\n",
        "    impl: 'simclrv1' or 'simclrv2'.  Whether to use simclrv1 or simclrv2's\r\n",
        "        version of random brightness.\r\n",
        "  Returns:\r\n",
        "    The distorted image tensor.\r\n",
        "  \"\"\"\r\n",
        "  with tf.name_scope('distort_color'):\r\n",
        "    def apply_transform(i, x):\r\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\r\n",
        "      def brightness_foo():\r\n",
        "        if brightness == 0:\r\n",
        "          return x\r\n",
        "        else:\r\n",
        "          return random_brightness(x, max_delta=brightness, impl=impl)\r\n",
        "\r\n",
        "      def contrast_foo():\r\n",
        "        if contrast == 0:\r\n",
        "          return x\r\n",
        "        else:\r\n",
        "          return tf.image.random_contrast(x, lower=1-contrast, upper=1+contrast)\r\n",
        "      def saturation_foo():\r\n",
        "        if saturation == 0:\r\n",
        "          return x\r\n",
        "        else:\r\n",
        "          return tf.image.random_saturation(\r\n",
        "              x, lower=1-saturation, upper=1+saturation)\r\n",
        "      def hue_foo():\r\n",
        "        if hue == 0:\r\n",
        "          return x\r\n",
        "        else:\r\n",
        "          return tf.image.random_hue(x, max_delta=hue)\r\n",
        "      x = tf.cond(tf.less(i, 2),\r\n",
        "                  lambda: tf.cond(tf.less(i, 1), brightness_foo, contrast_foo),\r\n",
        "                  lambda: tf.cond(tf.less(i, 3), saturation_foo, hue_foo))\r\n",
        "      return x\r\n",
        "\r\n",
        "    perm = tf.random.shuffle(tf.range(4))\r\n",
        "    for i in range(4):\r\n",
        "      image = apply_transform(perm[i], image)\r\n",
        "      #image = tf.clip_by_value(image, 0., 1.)\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def _compute_crop_shape(\r\n",
        "    image_height, image_width, aspect_ratio, crop_proportion):\r\n",
        "  \"\"\"Compute aspect ratio-preserving shape for central crop.\r\n",
        "  The resulting shape retains `crop_proportion` along one side and a proportion\r\n",
        "  less than or equal to `crop_proportion` along the other side.\r\n",
        "  Args:\r\n",
        "    image_height: Height of image to be cropped.\r\n",
        "    image_width: Width of image to be cropped.\r\n",
        "    aspect_ratio: Desired aspect ratio (width / height) of output.\r\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\r\n",
        "  Returns:\r\n",
        "    crop_height: Height of image after cropping.\r\n",
        "    crop_width: Width of image after cropping.\r\n",
        "  \"\"\"\r\n",
        "  image_width_float = tf.cast(image_width, tf.float32)\r\n",
        "  image_height_float = tf.cast(image_height, tf.float32)\r\n",
        "\r\n",
        "  def _requested_aspect_ratio_wider_than_image():\r\n",
        "    crop_height = tf.cast(\r\n",
        "        tf.math.rint(crop_proportion / aspect_ratio * image_width_float),\r\n",
        "        tf.int32)\r\n",
        "    crop_width = tf.cast(\r\n",
        "        tf.math.rint(crop_proportion * image_width_float), tf.int32)\r\n",
        "    return crop_height, crop_width\r\n",
        "\r\n",
        "  def _image_wider_than_requested_aspect_ratio():\r\n",
        "    crop_height = tf.cast(\r\n",
        "        tf.math.rint(crop_proportion * image_height_float), tf.int32)\r\n",
        "    crop_width = tf.cast(\r\n",
        "        tf.math.rint(crop_proportion * aspect_ratio * image_height_float),\r\n",
        "        tf.int32)\r\n",
        "    return crop_height, crop_width\r\n",
        "\r\n",
        "  return tf.cond(\r\n",
        "      aspect_ratio > image_width_float / image_height_float,\r\n",
        "      _requested_aspect_ratio_wider_than_image,\r\n",
        "      _image_wider_than_requested_aspect_ratio)\r\n",
        "\r\n",
        "\r\n",
        "def center_crop(image, height, width, crop_proportion):\r\n",
        "  \"\"\"Crops to center of image and rescales to desired size.\r\n",
        "  Args:\r\n",
        "    image: Image Tensor to crop.\r\n",
        "    height: Height of image to be cropped.\r\n",
        "    width: Width of image to be cropped.\r\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\r\n",
        "  Returns:\r\n",
        "    A `height` x `width` x channels Tensor holding a central crop of `image`.\r\n",
        "  \"\"\"\r\n",
        "  shape = tf.shape(image)\r\n",
        "  image_height = shape[0]\r\n",
        "  image_width = shape[1]\r\n",
        "  crop_height, crop_width = _compute_crop_shape(\r\n",
        "      image_height, image_width, height / width, crop_proportion)\r\n",
        "  offset_height = ((image_height - crop_height) + 1) // 2\r\n",
        "  offset_width = ((image_width - crop_width) + 1) // 2\r\n",
        "  image = tf.image.crop_to_bounding_box(\r\n",
        "      image, offset_height, offset_width, crop_height, crop_width)\r\n",
        "\r\n",
        "  image = tf.image.resize([image], [height, width],\r\n",
        "                          method=tf.image.ResizeMethod.BICUBIC)[0]\r\n",
        "\r\n",
        "  return image\r\n",
        "\r\n",
        "\r\n",
        "def distorted_bounding_box_crop(image,\r\n",
        "                                bbox,\r\n",
        "                                min_object_covered=0.1,\r\n",
        "                                aspect_ratio_range=(0.75, 1.33),\r\n",
        "                                area_range=(0.05, 1.0),\r\n",
        "                                max_attempts=100,\r\n",
        "                                scope=None):\r\n",
        "  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\r\n",
        "  See `tf.image.sample_distorted_bounding_box` for more documentation.\r\n",
        "  Args:\r\n",
        "    image: `Tensor` of image data.\r\n",
        "    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\r\n",
        "        where each coordinate is [0, 1) and the coordinates are arranged\r\n",
        "        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\r\n",
        "        image.\r\n",
        "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\r\n",
        "        area of the image must contain at least this fraction of any bounding\r\n",
        "        box supplied.\r\n",
        "    aspect_ratio_range: An optional list of `float`s. The cropped area of the\r\n",
        "        image must have an aspect ratio = width / height within this range.\r\n",
        "    area_range: An optional list of `float`s. The cropped area of the image\r\n",
        "        must contain a fraction of the supplied image within in this range.\r\n",
        "    max_attempts: An optional `int`. Number of attempts at generating a cropped\r\n",
        "        region of the image of the specified constraints. After `max_attempts`\r\n",
        "        failures, return the entire image.\r\n",
        "    scope: Optional `str` for name scope.\r\n",
        "  Returns:\r\n",
        "    (cropped image `Tensor`, distorted bbox `Tensor`).\r\n",
        "  \"\"\"\r\n",
        "  with tf.name_scope(scope or 'distorted_bounding_box_crop'):\r\n",
        "    shape = tf.shape(image)\r\n",
        "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\r\n",
        "        shape,\r\n",
        "        bounding_boxes=bbox,\r\n",
        "        min_object_covered=min_object_covered,\r\n",
        "        aspect_ratio_range=aspect_ratio_range,\r\n",
        "        area_range=area_range,\r\n",
        "        max_attempts=max_attempts,\r\n",
        "        use_image_if_no_bounding_boxes=True)\r\n",
        "    bbox_begin, bbox_size, _ = sample_distorted_bounding_box\r\n",
        "\r\n",
        "    # Crop the image to the specified bounding box.\r\n",
        "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\r\n",
        "    target_height, target_width, _ = tf.unstack(bbox_size)\r\n",
        "    image = tf.image.crop_to_bounding_box(\r\n",
        "        image, offset_y, offset_x, target_height, target_width)\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def crop_and_resize(image, height, width, \r\n",
        "                    aspect_ratio_fraction = (3./4., 4./3.),\r\n",
        "                    area_range         = (0.5, 1.0)):\r\n",
        "  \"\"\"Make a random crop and resize it to height `height` and width `width`.\r\n",
        "  Args:\r\n",
        "    image: Tensor representing the image.\r\n",
        "    height: Desired image height.\r\n",
        "    width: Desired image width.\r\n",
        "  Returns:\r\n",
        "    A `height` x `width` x channels Tensor holding a random crop of `image`.\r\n",
        "  \"\"\"\r\n",
        "  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\r\n",
        "  aspect_ratio = width / height\r\n",
        "  image = distorted_bounding_box_crop(\r\n",
        "      image,\r\n",
        "      bbox,\r\n",
        "      min_object_covered=0.1,\r\n",
        "      # aspect_ratio_range=(3. / 4 * aspect_ratio, 4. / 3. * aspect_ratio),\r\n",
        "      aspect_ratio_range=(aspect_ratio_fraction[0]*aspect_ratio, \r\n",
        "                          aspect_ratio_fraction[0]*aspect_ratio),\r\n",
        "      area_range=area_range,\r\n",
        "      max_attempts=100,\r\n",
        "      scope=None)\r\n",
        "  return tf.image.resize([image], [height, width],\r\n",
        "                         method=tf.image.ResizeMethod.BICUBIC)[0]\r\n",
        "\r\n",
        "\r\n",
        "def gaussian_blur(image, kernel_size, sigma, padding='SAME'):\r\n",
        "  \"\"\"Blurs the given image with separable convolution.\r\n",
        "  Args:\r\n",
        "    image: Tensor of shape [height, width, channels] and dtype float to blur.\r\n",
        "    kernel_size: Integer Tensor for the size of the blur kernel. This is should\r\n",
        "      be an odd number. If it is an even number, the actual kernel size will be\r\n",
        "      size + 1.\r\n",
        "    sigma: Sigma value for gaussian operator.\r\n",
        "    padding: Padding to use for the convolution. Typically 'SAME' or 'VALID'.\r\n",
        "  Returns:\r\n",
        "    A Tensor representing the blurred image.\r\n",
        "  \"\"\"\r\n",
        "  radius = tf.cast(kernel_size / 2, dtype=tf.int32)\r\n",
        "  kernel_size = radius * 2 + 1\r\n",
        "  x = tf.cast(tf.range(-radius, radius + 1), dtype=tf.float32)\r\n",
        "  blur_filter = tf.exp(-tf.pow(x, 2.0) /\r\n",
        "                       (2.0 * tf.pow(tf.cast(sigma, dtype=tf.float32), 2.0)))\r\n",
        "  blur_filter /= tf.reduce_sum(blur_filter)\r\n",
        "  # One vertical and one horizontal filter.\r\n",
        "  blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\r\n",
        "  blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\r\n",
        "  num_channels = tf.shape(image)[-1]\r\n",
        "  blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\r\n",
        "  blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\r\n",
        "  expand_batch_dim = image.shape.ndims == 3\r\n",
        "  if expand_batch_dim:\r\n",
        "    # Tensorflow requires batched input to convolutions, which we can fake with\r\n",
        "    # an extra dimension.\r\n",
        "    image = tf.expand_dims(image, axis=0)\r\n",
        "  blurred = tf.nn.depthwise_conv2d(\r\n",
        "      image, blur_h, strides=[1, 1, 1, 1], padding=padding)\r\n",
        "  blurred = tf.nn.depthwise_conv2d(\r\n",
        "      blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\r\n",
        "  if expand_batch_dim:\r\n",
        "    blurred = tf.squeeze(blurred, axis=0)\r\n",
        "  return blurred\r\n",
        "\r\n",
        "\r\n",
        "def random_crop_with_resize(image, height, width, p=1.0):\r\n",
        "  \"\"\"Randomly crop and resize an image.\r\n",
        "  Args:\r\n",
        "    image: `Tensor` representing an image of arbitrary size.\r\n",
        "    height: Height of output image.\r\n",
        "    width: Width of output image.\r\n",
        "    p: Probability of applying this transformation.\r\n",
        "  Returns:\r\n",
        "    A preprocessed image `Tensor`.\r\n",
        "  \"\"\"\r\n",
        "  def _transform(image):  # pylint: disable=missing-docstring\r\n",
        "    image = crop_and_resize(image, height, width)\r\n",
        "    return image\r\n",
        "  return random_apply(_transform, p=p, x=image)\r\n",
        "\r\n",
        "\r\n",
        "def random_color_jitter(image, p=1.0, impl='simclrv2', color_jitter_strength=0.5):\r\n",
        "\r\n",
        "  def _transform(image):\r\n",
        "    color_jitter_t = functools.partial(\r\n",
        "        color_jitter, strength=color_jitter_strength, impl=impl)\r\n",
        "    image = random_apply(color_jitter_t, p=0.8, x=image)\r\n",
        "    return random_apply(to_grayscale, p=0.2, x=image)\r\n",
        "  return random_apply(_transform, p=p, x=image)\r\n",
        "\r\n",
        "\r\n",
        "def random_blur(image, height, width, p=1.0):\r\n",
        "  \"\"\"Randomly blur an image.\r\n",
        "  Args:\r\n",
        "    image: `Tensor` representing an image of arbitrary size.\r\n",
        "    height: Height of output image.\r\n",
        "    width: Width of output image.\r\n",
        "    p: probability of applying this transformation.\r\n",
        "  Returns:\r\n",
        "    A preprocessed image `Tensor`.\r\n",
        "  \"\"\"\r\n",
        "  del width\r\n",
        "  def _transform(image):\r\n",
        "    sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\r\n",
        "    return gaussian_blur(\r\n",
        "        image, kernel_size=height//10, sigma=sigma, padding='SAME')\r\n",
        "  return random_apply(_transform, p=p, x=image)\r\n",
        "\r\n",
        "\r\n",
        "def batch_random_blur(images_list, height, width, blur_probability=0.5):\r\n",
        "  \"\"\"Apply efficient batch data transformations.\r\n",
        "  Args:\r\n",
        "    images_list: a list of image tensors.\r\n",
        "    height: the height of image.\r\n",
        "    width: the width of image.\r\n",
        "    blur_probability: the probaility to apply the blur operator.\r\n",
        "  Returns:\r\n",
        "    Preprocessed feature list.\r\n",
        "  \"\"\"\r\n",
        "  def generate_selector(p, bsz):\r\n",
        "    shape = [bsz, 1, 1, 1]\r\n",
        "    selector = tf.cast(\r\n",
        "        tf.less(tf.random.uniform(shape, 0, 1, dtype=tf.float32), p),\r\n",
        "        tf.float32)\r\n",
        "    return selector\r\n",
        "\r\n",
        "  new_images_list = []\r\n",
        "  for images in images_list:\r\n",
        "    images_new = random_blur(images, height, width, p=1.)\r\n",
        "    selector = generate_selector(blur_probability, tf.shape(images)[0])\r\n",
        "    images = images_new * selector + images * (1 - selector)\r\n",
        "    images = tf.clip_by_value(images, 0., 1.)\r\n",
        "    new_images_list.append(images)\r\n",
        "\r\n",
        "  return new_images_list\r\n",
        "\r\n",
        "\r\n",
        "def preprocess_for_train(image,\r\n",
        "                         height,\r\n",
        "                         width,\r\n",
        "                         color_distort=True,\r\n",
        "                         crop=True,\r\n",
        "                         flip=True,\r\n",
        "                         color_jitter_strength=0.9,\r\n",
        "                         impl='simclrv2'):\r\n",
        "  \"\"\"Preprocesses the given image for training.\r\n",
        "  Args:\r\n",
        "    image: `Tensor` representing an image of arbitrary size.\r\n",
        "    height: Height of output image.\r\n",
        "    width: Width of output image.\r\n",
        "    color_distort: Whether to apply the color distortion.\r\n",
        "    crop: Whether to crop the image.\r\n",
        "    flip: Whether or not to flip left and right of an image.\r\n",
        "    impl: 'simclrv1' or 'simclrv2'.  Whether to use simclrv1 or simclrv2's\r\n",
        "        version of random brightness.\r\n",
        "  Returns:\r\n",
        "    A preprocessed image `Tensor`.\r\n",
        "  \"\"\"\r\n",
        "  if crop:\r\n",
        "    image = random_crop_with_resize(image, height, width)\r\n",
        "  if flip:\r\n",
        "    image = tf.image.random_flip_left_right(image)\r\n",
        "  if color_distort:\r\n",
        "    image = random_color_jitter(image, impl=impl, \r\n",
        "                                color_jitter_strength=color_jitter_strength)\r\n",
        "  image = tf.reshape(image, [height, width, 3])\r\n",
        "  image = tf.clip_by_value(image, 0., 1.)\r\n",
        "  return image\r\n",
        "\r\n",
        "##################################################################################\r\n",
        "\r\n",
        "st.write(\"# Understand what happens during a augmentation!!\")\r\n",
        "st.sidebar.header('User Input Parameters')\r\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\r\n",
        " \r\n",
        "def user_input_augmentation():\r\n",
        "  # rotation = st.sidebar.slider('Rotation', 0., 180., 10.)\r\n",
        "  hue      = st.sidebar.slider('Hue', -1., 1., 0.1)\r\n",
        "  brightness= st.sidebar.slider('Brightness', -1., 1., 0.1)\r\n",
        "  contrast  = st.sidebar.slider('Contrast', -1., 1., 0.1)\r\n",
        "  saturation  = st.sidebar.slider('Saturation', -1., 1., 0.1)\r\n",
        "\r\n",
        "  data = {\r\n",
        "    'hue': hue,\r\n",
        "    'brightness': brightness,\r\n",
        "    'contrast': contrast,\r\n",
        "    'saturation': saturation\r\n",
        "  }\r\n",
        "  features = pd.DataFrame(data, index=[0])\r\n",
        "  return features\r\n",
        "df = user_input_augmentation()\r\n",
        "st.subheader('User Input parameters')\r\n",
        "st.write(df)\r\n",
        "\r\n",
        "\r\n",
        "def simclr_augmentation():\r\n",
        "  # rotation = st.sidebar.slider('Rotation', 0., 180., 10.)\r\n",
        "  color_jitter_strength   = st.sidebar.slider('Color Jitter Strength', 0.01, 0.99, 0.05)\r\n",
        "  random_blur_probability = st.sidebar.slider('Random Blur Prob', 0.01, 0.99, 0.05)\r\n",
        "\r\n",
        "  data = {\r\n",
        "    'color_jitter_strength': color_jitter_strength,\r\n",
        "    'random_blur': random_blur_probability\r\n",
        "  }\r\n",
        "  features = pd.DataFrame(data, index=[0])\r\n",
        "  return features\r\n",
        "\r\n",
        "\r\n",
        "tfdf = simclr_augmentation()\r\n",
        "st.subheader('Tensorflow Aug parameters')\r\n",
        "st.write(tfdf)\r\n",
        "\r\n",
        "\r\n",
        "def image_aug(img, features):\r\n",
        "  # img = tf.image.rotation(img, features['rotation'])\r\n",
        "  img = img[tf.newaxis,...]\r\n",
        "  img = tf.image.adjust_brightness(img, features['brightness'].values[0])\r\n",
        "  img = tf.image.adjust_contrast(img, features['contrast'].values[0])\r\n",
        "  img = tf.image.adjust_hue(img, features['hue'].values[0])\r\n",
        "  img = tf.image.adjust_saturation(img, features['saturation'].values[0])\r\n",
        "  img = tf.clip_by_value(img, 0, 255)\r\n",
        "  return img[0].numpy()\r\n",
        "\r\n",
        "st.subheader('Class labels and their corresponding index number')\r\n",
        "st.image([x_train[0].astype(np.uint8), image_aug(x_train[0], df).astype(np.uint8)],\r\n",
        "          width=224)\r\n",
        "\r\n",
        "st.subheader('SimCLR')\r\n",
        "\r\n",
        "nrows = 4\r\n",
        "ncols = 4\r\n",
        "for r in range(nrows):\r\n",
        "  image_list = [preprocess_for_train(x_train[r*ncols + i]/255., 32, 32, \r\n",
        "                                     color_jitter_strength = float(tfdf['color_jitter_strength'].values[0])) for i in range(ncols)]\r\n",
        "  blur_image_list = [random_blur(img, 32, 32, p= float(tfdf['random_blur'].values[0])) for img in image_list]\r\n",
        "  image_list      = [ ( tf.clip_by_value(img, 0, 1).numpy()*255).astype(np.uint8) for img in blur_image_list]\r\n",
        "  st.image(image_list, width=112)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting img_aug.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crutm2ao_qGV",
        "outputId": "288684e9-e314-495e-afa2-235904c857f8"
      },
      "source": [
        "!streamlit run img_aug.py &>/dev/null&\r\n",
        "!npx localtunnel --port 8501"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 35 in 3.502s\n",
            "your url is: https://tricky-cheetah-19.loca.lt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}